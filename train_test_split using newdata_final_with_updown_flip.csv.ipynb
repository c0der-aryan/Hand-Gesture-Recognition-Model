{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40d92473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cfc5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e919c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/aryansood/aims/AIMS_DRONE2/newdata_final_with_updown_flip.csv\")\n",
    "df_shuffled = df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea31945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_shuffled.drop('label', axis=1)  # Features\n",
    "y = df_shuffled['label']  # Labels\n",
    "\n",
    "# Split the shuffled data into 80% training, 10% validation, and 10% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e14e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 80.46%\n",
      "Test Accuracy: 77.14%\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9f1358a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 13:14:22,362] A new study created in memory with name: no-name-8ae75d92-6e07-484b-8f8b-88114f47d9fe\n",
      "[I 2024-01-24 13:14:23,069] Trial 0 finished with value: 0.7514792899408284 and parameters: {'n_estimators': 170, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7514792899408284.\n",
      "[I 2024-01-24 13:14:23,716] Trial 1 finished with value: 0.757396449704142 and parameters: {'n_estimators': 161, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.757396449704142.\n",
      "[I 2024-01-24 13:14:23,950] Trial 2 finished with value: 0.7751479289940828 and parameters: {'n_estimators': 58, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7751479289940828.\n",
      "[I 2024-01-24 13:14:24,574] Trial 3 finished with value: 0.7633136094674556 and parameters: {'n_estimators': 146, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7751479289940828.\n",
      "[I 2024-01-24 13:14:24,928] Trial 4 finished with value: 0.7633136094674556 and parameters: {'n_estimators': 85, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7751479289940828.\n",
      "[I 2024-01-24 13:14:25,316] Trial 5 finished with value: 0.7633136094674556 and parameters: {'n_estimators': 90, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7751479289940828.\n",
      "[I 2024-01-24 13:14:26,069] Trial 6 finished with value: 0.7633136094674556 and parameters: {'n_estimators': 181, 'max_depth': 19, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7751479289940828.\n",
      "[I 2024-01-24 13:14:26,371] Trial 7 finished with value: 0.7633136094674556 and parameters: {'n_estimators': 70, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7751479289940828.\n",
      "[I 2024-01-24 13:14:26,754] Trial 8 finished with value: 0.757396449704142 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7751479289940828.\n",
      "[I 2024-01-24 13:14:27,465] Trial 9 finished with value: 0.7633136094674556 and parameters: {'n_estimators': 176, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7751479289940828.\n",
      "[I 2024-01-24 13:14:27,809] Trial 10 finished with value: 0.7928994082840237 and parameters: {'n_estimators': 124, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.7928994082840237.\n",
      "[I 2024-01-24 13:14:28,093] Trial 11 finished with value: 0.7041420118343196 and parameters: {'n_estimators': 122, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.7928994082840237.\n",
      "[I 2024-01-24 13:14:28,263] Trial 12 finished with value: 0.7810650887573964 and parameters: {'n_estimators': 56, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.7928994082840237.\n",
      "[I 2024-01-24 13:14:28,549] Trial 13 finished with value: 0.7041420118343196 and parameters: {'n_estimators': 122, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.7928994082840237.\n",
      "[I 2024-01-24 13:14:29,243] Trial 14 finished with value: 0.7869822485207101 and parameters: {'n_estimators': 198, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.7928994082840237.\n",
      "[I 2024-01-24 13:14:29,943] Trial 15 finished with value: 0.7869822485207101 and parameters: {'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.7928994082840237.\n",
      "[I 2024-01-24 13:14:30,453] Trial 16 finished with value: 0.7751479289940828 and parameters: {'n_estimators': 148, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.7928994082840237.\n",
      "[I 2024-01-24 13:14:30,832] Trial 17 finished with value: 0.7810650887573964 and parameters: {'n_estimators': 109, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.7928994082840237.\n",
      "[I 2024-01-24 13:14:31,464] Trial 18 finished with value: 0.757396449704142 and parameters: {'n_estimators': 142, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.7928994082840237.\n",
      "[I 2024-01-24 13:14:32,187] Trial 19 finished with value: 0.7751479289940828 and parameters: {'n_estimators': 198, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.7928994082840237.\n",
      "[I 2024-01-24 13:14:32,789] Trial 20 finished with value: 0.757396449704142 and parameters: {'n_estimators': 135, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.7928994082840237.\n",
      "[I 2024-01-24 13:14:33,400] Trial 21 finished with value: 0.7988165680473372 and parameters: {'n_estimators': 197, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.7988165680473372.\n",
      "[I 2024-01-24 13:14:33,987] Trial 22 finished with value: 0.7988165680473372 and parameters: {'n_estimators': 189, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.7988165680473372.\n",
      "[I 2024-01-24 13:14:34,491] Trial 23 finished with value: 0.7928994082840237 and parameters: {'n_estimators': 185, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.7988165680473372.\n",
      "[I 2024-01-24 13:14:34,990] Trial 24 finished with value: 0.7988165680473372 and parameters: {'n_estimators': 160, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.7988165680473372.\n",
      "[I 2024-01-24 13:14:35,589] Trial 25 finished with value: 0.7633136094674556 and parameters: {'n_estimators': 162, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.7988165680473372.\n",
      "[I 2024-01-24 13:14:36,326] Trial 26 finished with value: 0.757396449704142 and parameters: {'n_estimators': 188, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.7988165680473372.\n",
      "[I 2024-01-24 13:14:37,071] Trial 27 finished with value: 0.7633136094674556 and parameters: {'n_estimators': 167, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.7988165680473372.\n",
      "[I 2024-01-24 13:14:37,561] Trial 28 finished with value: 0.7751479289940828 and parameters: {'n_estimators': 157, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.7988165680473372.\n",
      "[I 2024-01-24 13:14:38,099] Trial 29 finished with value: 0.7928994082840237 and parameters: {'n_estimators': 173, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.7988165680473372.\n",
      "[I 2024-01-24 13:14:38,838] Trial 30 finished with value: 0.7514792899408284 and parameters: {'n_estimators': 188, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.7988165680473372.\n",
      "[I 2024-01-24 13:14:39,203] Trial 31 finished with value: 0.8106508875739645 and parameters: {'n_estimators': 132, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:39,691] Trial 32 finished with value: 0.7928994082840237 and parameters: {'n_estimators': 156, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:40,092] Trial 33 finished with value: 0.6982248520710059 and parameters: {'n_estimators': 174, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:40,591] Trial 34 finished with value: 0.757396449704142 and parameters: {'n_estimators': 133, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:40,938] Trial 35 finished with value: 0.7988165680473372 and parameters: {'n_estimators': 109, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 13:14:41,686] Trial 36 finished with value: 0.7514792899408284 and parameters: {'n_estimators': 190, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:42,101] Trial 37 finished with value: 0.7869822485207101 and parameters: {'n_estimators': 151, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:42,811] Trial 38 finished with value: 0.7633136094674556 and parameters: {'n_estimators': 165, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:43,076] Trial 39 finished with value: 0.6804733727810651 and parameters: {'n_estimators': 112, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:43,841] Trial 40 finished with value: 0.7633136094674556 and parameters: {'n_estimators': 179, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:44,176] Trial 41 finished with value: 0.7869822485207101 and parameters: {'n_estimators': 105, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:44,417] Trial 42 finished with value: 0.7869822485207101 and parameters: {'n_estimators': 74, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:44,837] Trial 43 finished with value: 0.7633136094674556 and parameters: {'n_estimators': 101, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:45,155] Trial 44 finished with value: 0.7751479289940828 and parameters: {'n_estimators': 114, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:45,483] Trial 45 finished with value: 0.7514792899408284 and parameters: {'n_estimators': 85, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:46,040] Trial 46 finished with value: 0.7633136094674556 and parameters: {'n_estimators': 131, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:46,373] Trial 47 finished with value: 0.6863905325443787 and parameters: {'n_estimators': 142, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:47,073] Trial 48 finished with value: 0.7810650887573964 and parameters: {'n_estimators': 193, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8106508875739645.\n",
      "[I 2024-01-24 13:14:47,574] Trial 49 finished with value: 0.7869822485207101 and parameters: {'n_estimators': 183, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 31 with value: 0.8106508875739645.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 132, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 1}\n",
      "Best Validation Accuracy: 81.07%\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "    }\n",
    "\n",
    "    # Initialize and train the Random Forest Classifier with the suggested hyperparameters\n",
    "    rf_clf = RandomForestClassifier(**params, random_state=42)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = rf_clf.predict(X_val)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "study.optimize(objective, n_trials=50)  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and their corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c727471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 79.29%\n",
      "Test Accuracy: 82.94%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the KNN model\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = knn_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = knn_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {accuracy_test * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57d838af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 13:14:55,671] A new study created in memory with name: no-name-3de28c1a-d0f4-4f27-a8dc-87d58d8ed49d\n",
      "[I 2024-01-24 13:14:55,710] Trial 0 finished with value: 0.7970479704797048 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'p': 2}. Best is trial 0 with value: 0.7970479704797048.\n",
      "[I 2024-01-24 13:14:55,772] Trial 1 finished with value: 0.7785977859778598 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'p': 1}. Best is trial 0 with value: 0.7970479704797048.\n",
      "[I 2024-01-24 13:14:55,806] Trial 2 finished with value: 0.7896678966789668 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'p': 2}. Best is trial 0 with value: 0.7970479704797048.\n",
      "[I 2024-01-24 13:14:55,834] Trial 3 finished with value: 0.7896678966789668 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 2}. Best is trial 0 with value: 0.7970479704797048.\n",
      "[I 2024-01-24 13:14:55,864] Trial 4 finished with value: 0.7785977859778598 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'p': 1}. Best is trial 0 with value: 0.7970479704797048.\n",
      "[I 2024-01-24 13:14:55,892] Trial 5 finished with value: 0.7970479704797048 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'p': 2}. Best is trial 0 with value: 0.7970479704797048.\n",
      "[I 2024-01-24 13:14:55,921] Trial 6 finished with value: 0.7933579335793358 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'p': 2}. Best is trial 0 with value: 0.7970479704797048.\n",
      "[I 2024-01-24 13:14:55,961] Trial 7 finished with value: 0.7822878228782287 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'p': 1}. Best is trial 0 with value: 0.7970479704797048.\n",
      "[I 2024-01-24 13:14:56,010] Trial 8 finished with value: 0.7749077490774908 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'p': 1}. Best is trial 0 with value: 0.7970479704797048.\n",
      "[I 2024-01-24 13:14:56,056] Trial 9 finished with value: 0.7896678966789668 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'p': 2}. Best is trial 0 with value: 0.7970479704797048.\n",
      "[I 2024-01-24 13:14:56,098] Trial 10 finished with value: 0.7970479704797048 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'p': 2}. Best is trial 0 with value: 0.7970479704797048.\n",
      "[I 2024-01-24 13:14:56,160] Trial 11 finished with value: 0.7970479704797048 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'p': 2}. Best is trial 0 with value: 0.7970479704797048.\n",
      "[I 2024-01-24 13:14:56,237] Trial 12 finished with value: 0.8007380073800738 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'p': 2}. Best is trial 12 with value: 0.8007380073800738.\n",
      "[I 2024-01-24 13:14:56,281] Trial 13 finished with value: 0.8007380073800738 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'p': 2}. Best is trial 12 with value: 0.8007380073800738.\n",
      "[I 2024-01-24 13:14:56,319] Trial 14 finished with value: 0.8007380073800738 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'p': 2}. Best is trial 12 with value: 0.8007380073800738.\n",
      "[I 2024-01-24 13:14:56,371] Trial 15 finished with value: 0.8007380073800738 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'p': 2}. Best is trial 12 with value: 0.8007380073800738.\n",
      "[I 2024-01-24 13:14:56,421] Trial 16 finished with value: 0.8007380073800738 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'p': 2}. Best is trial 12 with value: 0.8007380073800738.\n",
      "[I 2024-01-24 13:14:56,456] Trial 17 finished with value: 0.7822878228782287 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'p': 1}. Best is trial 12 with value: 0.8007380073800738.\n",
      "[I 2024-01-24 13:14:56,487] Trial 18 finished with value: 0.7859778597785978 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'p': 2}. Best is trial 12 with value: 0.8007380073800738.\n",
      "[I 2024-01-24 13:14:56,539] Trial 19 finished with value: 0.8081180811808119 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'p': 2}. Best is trial 19 with value: 0.8081180811808119.\n",
      "[I 2024-01-24 13:14:56,589] Trial 20 finished with value: 0.7933579335793358 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'p': 1}. Best is trial 19 with value: 0.8081180811808119.\n",
      "[I 2024-01-24 13:14:56,639] Trial 21 finished with value: 0.8081180811808119 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'p': 2}. Best is trial 19 with value: 0.8081180811808119.\n",
      "[I 2024-01-24 13:14:56,686] Trial 22 finished with value: 0.8081180811808119 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'p': 2}. Best is trial 19 with value: 0.8081180811808119.\n",
      "[I 2024-01-24 13:14:56,736] Trial 23 finished with value: 0.8118081180811808 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'p': 2}. Best is trial 23 with value: 0.8118081180811808.\n",
      "[I 2024-01-24 13:14:56,806] Trial 24 finished with value: 0.8118081180811808 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'p': 2}. Best is trial 23 with value: 0.8118081180811808.\n",
      "[I 2024-01-24 13:14:56,851] Trial 25 finished with value: 0.8228782287822878 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:56,886] Trial 26 finished with value: 0.7896678966789668 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:56,932] Trial 27 finished with value: 0.8228782287822878 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:56,969] Trial 28 finished with value: 0.8228782287822878 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,005] Trial 29 finished with value: 0.8228782287822878 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,040] Trial 30 finished with value: 0.8228782287822878 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,092] Trial 31 finished with value: 0.8228782287822878 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,128] Trial 32 finished with value: 0.7970479704797048 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,174] Trial 33 finished with value: 0.8228782287822878 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,221] Trial 34 finished with value: 0.7970479704797048 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,258] Trial 35 finished with value: 0.8228782287822878 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,305] Trial 36 finished with value: 0.8118081180811808 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,352] Trial 37 finished with value: 0.7970479704797048 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,400] Trial 38 finished with value: 0.8228782287822878 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,466] Trial 39 finished with value: 0.7896678966789668 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,514] Trial 40 finished with value: 0.7822878228782287 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,545] Trial 41 finished with value: 0.8228782287822878 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,608] Trial 42 finished with value: 0.7970479704797048 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 13:14:57,658] Trial 43 finished with value: 0.8228782287822878 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,707] Trial 44 finished with value: 0.8118081180811808 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,754] Trial 45 finished with value: 0.7970479704797048 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,796] Trial 46 finished with value: 0.8228782287822878 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,855] Trial 47 finished with value: 0.8118081180811808 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,898] Trial 48 finished with value: 0.7970479704797048 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n",
      "[I 2024-01-24 13:14:57,928] Trial 49 finished with value: 0.7933579335793358 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'p': 2}. Best is trial 25 with value: 0.8228782287822878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}\n",
      "Best Validation Accuracy: 82.29%\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'X_train' and 'y_train' are your training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'n_neighbors': trial.suggest_int('n_neighbors', 1, 10),\n",
    "        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "        'p': trial.suggest_int('p', 1, 2),\n",
    "    }\n",
    "\n",
    "    # Initialize and train the K-Nearest Neighbors model with the suggested hyperparameters\n",
    "    knn_clf = KNeighborsClassifier(**params)\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = knn_clf.predict(X_val)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and their corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c431535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Perceptron, PassiveAggressiveClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "def compare_classifiers(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    # Define classifiers\n",
    "#     classifiers = {\n",
    "#         'Random Forest': RandomForestClassifier(random_state=42),\n",
    "#         'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "#         'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "#         'Support Vector Machine': SVC(random_state=42),\n",
    "# #         'Logistic Regression': LogisticRegression(max_iter=10000, random_state=42),\n",
    "#         'Naive Bayes': GaussianNB(),\n",
    "#         'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "#         'Neural Network': MLPClassifier(random_state=42),\n",
    "#         'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "#         'Bagging Classifier': BaggingClassifier(random_state=42),\n",
    "#         'Extra Trees Classifier': ExtraTreesClassifier(random_state=42),\n",
    "#         'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
    "#         'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(),\n",
    "#         'Gaussian Process Classifier': GaussianProcessClassifier(random_state=42),\n",
    "#         'XGBoost': XGBClassifier(random_state=42)\n",
    "#     }\n",
    "    \n",
    "    classifiers = {\n",
    "    'Support Vector Classifier': SVC(),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier(),\n",
    "    'Random Forest Classifier': RandomForestClassifier(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Bernoulli Naive Bayes': BernoulliNB(),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier(),\n",
    "    'XGBoost Classifier': XGBClassifier(),\n",
    "    'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
    "    'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(),\n",
    "    'Bagging Classifier': BaggingClassifier(),\n",
    "    'Extra Trees Classifier': ExtraTreesClassifier(),\n",
    "    'Passive Aggressive Classifier': PassiveAggressiveClassifier(),\n",
    "    'Perceptron': Perceptron(),\n",
    "    'Ridge Classifier': RidgeClassifier(),\n",
    "    }\n",
    "\n",
    "\n",
    "    # Train and evaluate each classifier on the validation set\n",
    "    val_results = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val, y_val_pred)\n",
    "        val_results[name] = accuracy\n",
    "\n",
    "    # Sort validation results by accuracy in descending order\n",
    "    val_results = {k: v for k, v in sorted(val_results.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    # Print the validation results\n",
    "    print(\"Classifier Performance on Validation Set:\")\n",
    "    for name, accuracy in val_results.items():\n",
    "        print(f\"{name}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Train and evaluate each classifier on the test set\n",
    "    test_results = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        test_results[name] = accuracy\n",
    "\n",
    "    # Sort test results by accuracy in descending order\n",
    "    test_results = {k: v for k, v in sorted(test_results.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    # Print the test results\n",
    "    print(\"\\nClassifier Performance on Test Set:\")\n",
    "    for name, accuracy in test_results.items():\n",
    "        print(f\"{name}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Example usage:\n",
    "# compare_classifiers(X_train, X_val, X_test, y_train, y_val, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d48a4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Performance on Validation Set:\n",
      "Ridge Classifier: 87.57%\n",
      "Linear Discriminant Analysis: 86.98%\n",
      "Passive Aggressive Classifier: 85.80%\n",
      "Perceptron: 85.21%\n",
      "Support Vector Classifier: 84.62%\n",
      "Quadratic Discriminant Analysis: 79.88%\n",
      "K-Nearest Neighbors: 79.29%\n",
      "Random Forest Classifier: 76.33%\n",
      "Gradient Boosting Classifier: 75.74%\n",
      "Extra Trees Classifier: 75.74%\n",
      "XGBoost Classifier: 75.15%\n",
      "Bagging Classifier: 74.56%\n",
      "Decision Tree Classifier: 72.19%\n",
      "Gaussian Naive Bayes: 63.31%\n",
      "AdaBoost Classifier: 25.44%\n",
      "Bernoulli Naive Bayes: 18.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier Performance on Test Set:\n",
      "Support Vector Classifier: 88.82%\n",
      "Passive Aggressive Classifier: 88.82%\n",
      "Perceptron: 87.65%\n",
      "Ridge Classifier: 87.06%\n",
      "Linear Discriminant Analysis: 85.29%\n",
      "K-Nearest Neighbors: 82.94%\n",
      "Quadratic Discriminant Analysis: 82.94%\n",
      "Extra Trees Classifier: 80.00%\n",
      "Gradient Boosting Classifier: 79.41%\n",
      "XGBoost Classifier: 79.41%\n",
      "Random Forest Classifier: 78.82%\n",
      "Bagging Classifier: 75.88%\n",
      "Decision Tree Classifier: 74.12%\n",
      "Gaussian Naive Bayes: 65.29%\n",
      "AdaBoost Classifier: 23.53%\n",
      "Bernoulli Naive Bayes: 13.53%\n"
     ]
    }
   ],
   "source": [
    "compare_classifiers(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701536a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 87.36%\n",
      "Test Accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the Ridge Classifier model\n",
    "ridge_clf = RidgeClassifier()\n",
    "ridge_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = ridge_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy_val * 100:.2f}%\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = ridge_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {accuracy_test * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b267227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 13:49:32,132] A new study created in memory with name: no-name-e73003c7-5c7d-4461-96ea-83f44e03fadc\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:49:34,933] Trial 0 finished with value: 0.8781362007168458 and parameters: {'alpha': 1.6394413171252897, 'solver': 'saga'}. Best is trial 0 with value: 0.8781362007168458.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:35,034] Trial 1 finished with value: 0.8745519713261649 and parameters: {'alpha': 0.031075763172253888, 'solver': 'lsqr'}. Best is trial 0 with value: 0.8781362007168458.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:35,130] Trial 2 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.00046668235475350847, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:35,144] Trial 3 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.011529740133403108, 'solver': 'svd'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:35,237] Trial 4 finished with value: 0.8745519713261649 and parameters: {'alpha': 0.022719491699250693, 'solver': 'lsqr'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:35,355] Trial 5 finished with value: 0.8745519713261649 and parameters: {'alpha': 0.0023212913888270357, 'solver': 'lsqr'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:35,366] Trial 6 finished with value: 0.8817204301075269 and parameters: {'alpha': 12.909731591944182, 'solver': 'auto'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:35,504] Trial 7 finished with value: 0.8817204301075269 and parameters: {'alpha': 1.3969203313381757, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:35,526] Trial 8 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.003955285014960822, 'solver': 'auto'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:35,807] Trial 9 finished with value: 0.8745519713261649 and parameters: {'alpha': 0.00236361067452272, 'solver': 'lsqr'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:35,935] Trial 10 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.0001958732929762542, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:35,981] Trial 11 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.0002462300280524368, 'solver': 'svd'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:49:38,664] Trial 12 finished with value: 0.8781362007168458 and parameters: {'alpha': 0.16977441604149188, 'solver': 'sag'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:38,686] Trial 13 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.00012941753401600549, 'solver': 'svd'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:38,701] Trial 14 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.0011328230473998022, 'solver': 'cholesky'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:38,728] Trial 15 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.01662612172557457, 'solver': 'svd'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:38,836] Trial 16 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.27319988055743905, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:49:41,731] Trial 17 finished with value: 0.8781362007168458 and parameters: {'alpha': 61.53645792721574, 'solver': 'saga'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:49:44,304] Trial 18 finished with value: 0.8781362007168458 and parameters: {'alpha': 0.008482205085617566, 'solver': 'sag'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:44,311] Trial 19 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.0006872611081846719, 'solver': 'cholesky'}. Best is trial 2 with value: 0.8817204301075269.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:44,429] Trial 20 finished with value: 0.8745519713261649 and parameters: {'alpha': 0.049285745855624036, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:44,449] Trial 21 finished with value: 0.8745519713261649 and parameters: {'alpha': 84.55001944712677, 'solver': 'auto'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:44,470] Trial 22 finished with value: 0.8817204301075269 and parameters: {'alpha': 14.180299681927295, 'solver': 'auto'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:44,504] Trial 23 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.7902876574526239, 'solver': 'auto'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:44,536] Trial 24 finished with value: 0.8817204301075269 and parameters: {'alpha': 15.526273940276031, 'solver': 'svd'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:44,553] Trial 25 finished with value: 0.8817204301075269 and parameters: {'alpha': 4.42060604314611, 'solver': 'svd'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:44,669] Trial 26 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.0005840251163291691, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:44,685] Trial 27 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.4107844322026111, 'solver': 'auto'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:49:47,412] Trial 28 finished with value: 0.8781362007168458 and parameters: {'alpha': 0.060903877981748546, 'solver': 'sag'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:49:50,228] Trial 29 finished with value: 0.8781362007168458 and parameters: {'alpha': 3.6793187750269447, 'solver': 'saga'}. Best is trial 2 with value: 0.8817204301075269.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:50,240] Trial 30 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.007649679993235776, 'solver': 'cholesky'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:50,364] Trial 31 finished with value: 0.8817204301075269 and parameters: {'alpha': 1.5817203049829889, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:50,453] Trial 32 finished with value: 0.8781362007168458 and parameters: {'alpha': 14.499394754354334, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:50,539] Trial 33 finished with value: 0.8745519713261649 and parameters: {'alpha': 5.810228564542511, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:50,638] Trial 34 finished with value: 0.8817204301075269 and parameters: {'alpha': 1.2622925054672673, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:49:53,520] Trial 35 finished with value: 0.8781362007168458 and parameters: {'alpha': 0.10887886562568819, 'solver': 'saga'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:53,577] Trial 36 finished with value: 0.8745519713261649 and parameters: {'alpha': 29.0792649936928, 'solver': 'lsqr'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:53,594] Trial 37 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.5936113519632273, 'solver': 'auto'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:53,650] Trial 38 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.003024796523862246, 'solver': 'svd'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:53,784] Trial 39 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.020620377458759654, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:53,856] Trial 40 finished with value: 0.8745519713261649 and parameters: {'alpha': 0.00036100308931984827, 'solver': 'lsqr'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:53,877] Trial 41 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.0037316098096266503, 'solver': 'auto'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:53,897] Trial 42 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.0012670234463260583, 'solver': 'auto'}. Best is trial 2 with value: 0.8817204301075269.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:53,917] Trial 43 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.006616414401910067, 'solver': 'auto'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:53,941] Trial 44 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.0018889570494095478, 'solver': 'svd'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:53,960] Trial 45 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.011007181666626509, 'solver': 'auto'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:54,086] Trial 46 finished with value: 0.8745519713261649 and parameters: {'alpha': 0.0294024806425419, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:49:56,753] Trial 47 finished with value: 0.8781362007168458 and parameters: {'alpha': 0.00010870149638202298, 'solver': 'sag'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:56,760] Trial 48 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.004366191214823833, 'solver': 'cholesky'}. Best is trial 2 with value: 0.8817204301075269.\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_13076/239363571.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
      "[I 2024-01-24 13:49:56,800] Trial 49 finished with value: 0.8817204301075269 and parameters: {'alpha': 0.17638206025246927, 'solver': 'svd'}. Best is trial 2 with value: 0.8817204301075269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 0.00046668235475350847, 'solver': 'sparse_cg'}\n",
      "Best Validation Accuracy: 88.17%\n",
      "Test Accuracy: 86.29%\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'X_train' and 'y_train' are your training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
    "        'solver': trial.suggest_categorical('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'])\n",
    "    }\n",
    "\n",
    "    # Initialize and train the Ridge Classifier model with the suggested hyperparameters\n",
    "    ridge_clf = RidgeClassifier(**params)\n",
    "    ridge_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = ridge_clf.predict(X_val)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and their corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Use the best hyperparameters to train the final Ridge Classifier model\n",
    "final_ridge_clf = RidgeClassifier(**best_params)\n",
    "final_ridge_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best Ridge Classifier model\n",
    "y_test_pred = final_ridge_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# Best Hyperparameters: {'alpha': 0.00046668235475350847, 'solver': 'sparse_cg'}\n",
    "# Best Validation Accuracy: 88.17%\n",
    "# Test Accuracy: 86.29%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72b54689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 13:50:23,394] A new study created in memory with name: no-name-e64e894d-6624-4d37-b4c5-10fc275db6a2\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:25,656] Trial 0 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.00010687964225283955, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:50:25,771] Trial 1 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.1360765790919907, 'solver': 'sparse_cg'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:50:25,835] Trial 2 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.00026092176348772894, 'solver': 'sparse_cg'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:50:25,849] Trial 3 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.2874376071482597, 'solver': 'auto'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:50:25,924] Trial 4 finished with value: 0.8789237668161435 and parameters: {'alpha': 0.11419942351472363, 'solver': 'lsqr'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:50:26,049] Trial 5 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.0015300388417403901, 'solver': 'sparse_cg'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:28,222] Trial 6 finished with value: 0.8789237668161435 and parameters: {'alpha': 0.00013332988318315994, 'solver': 'sag'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:50:28,337] Trial 7 finished with value: 0.8789237668161435 and parameters: {'alpha': 0.01821618175171975, 'solver': 'lsqr'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:50:28,505] Trial 8 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.0008775070150728542, 'solver': 'sparse_cg'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:30,856] Trial 9 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.0023712319425688026, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:33,098] Trial 10 finished with value: 0.8834080717488789 and parameters: {'alpha': 22.611867698509833, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:35,340] Trial 11 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.005248440394619826, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:37,579] Trial 12 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.009087580346565809, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:50:37,599] Trial 13 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.0001285035418473126, 'solver': 'cholesky'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:50:37,803] Trial 14 finished with value: 0.8654708520179372 and parameters: {'alpha': 2.00838560116668, 'solver': 'svd'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:40,212] Trial 15 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.0011662822839799023, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:42,450] Trial 16 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.01908680813485107, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:50:42,473] Trial 17 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.0007138151215265315, 'solver': 'svd'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:50:42,487] Trial 18 finished with value: 0.8654708520179372 and parameters: {'alpha': 94.54084053692007, 'solver': 'auto'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:44,695] Trial 19 finished with value: 0.8789237668161435 and parameters: {'alpha': 0.0036710502244700007, 'solver': 'sag'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:50:44,703] Trial 20 finished with value: 0.8654708520179372 and parameters: {'alpha': 1.0605183844002106, 'solver': 'cholesky'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:47,047] Trial 21 finished with value: 0.8834080717488789 and parameters: {'alpha': 6.492166445337479, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:49,345] Trial 22 finished with value: 0.8834080717488789 and parameters: {'alpha': 59.01916543929019, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:51,577] Trial 23 finished with value: 0.8834080717488789 and parameters: {'alpha': 15.137065140692608, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:53,807] Trial 24 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.030412105244437843, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:56,033] Trial 25 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.00044073946391106895, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:50:58,259] Trial 26 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.9998377174374585, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:00,489] Trial 27 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.0023770315643996945, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:51:00,506] Trial 28 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.04978109965905621, 'solver': 'cholesky'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:51:00,518] Trial 29 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.29624841643120836, 'solver': 'svd'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:51:00,533] Trial 30 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.0003709481799317785, 'solver': 'auto'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:02,850] Trial 31 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.006801241175026185, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:05,077] Trial 32 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.0050143989416275665, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:07,364] Trial 33 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.00010380925913724467, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:09,447] Trial 34 finished with value: 0.8789237668161435 and parameters: {'alpha': 0.23815461182967113, 'solver': 'sag'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:51:09,497] Trial 35 finished with value: 0.8789237668161435 and parameters: {'alpha': 0.06589984396223728, 'solver': 'lsqr'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:51:09,566] Trial 36 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.0018506978841515273, 'solver': 'sparse_cg'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:11,868] Trial 37 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.012260987367191391, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:51:11,905] Trial 38 finished with value: 0.8789237668161435 and parameters: {'alpha': 0.0003511513569657844, 'solver': 'lsqr'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:51:11,925] Trial 39 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.13556917964743753, 'solver': 'auto'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:51:12,019] Trial 40 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.0002355864450167637, 'solver': 'sparse_cg'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:14,317] Trial 41 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.005923049977032445, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:16,569] Trial 42 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.009163514964011634, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:18,799] Trial 43 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.002583738372753477, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:21,055] Trial 44 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.0008125304352383701, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:23,292] Trial 45 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.0228292041119179, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:25,345] Trial 46 finished with value: 0.8789237668161435 and parameters: {'alpha': 0.04252828827974076, 'solver': 'sag'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:51:25,375] Trial 47 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.00020245923529872622, 'solver': 'svd'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "[I 2024-01-24 13:51:25,398] Trial 48 finished with value: 0.8654708520179372 and parameters: {'alpha': 0.01277153464140976, 'solver': 'cholesky'}. Best is trial 0 with value: 0.8834080717488789.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:51:27,796] Trial 49 finished with value: 0.8834080717488789 and parameters: {'alpha': 0.0012933124159103615, 'solver': 'saga'}. Best is trial 0 with value: 0.8834080717488789.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 0.00010687964225283955, 'solver': 'saga'}\n",
      "Best Validation Accuracy: 88.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'X_train' and 'y_train' are your training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'alpha': trial.suggest_float('alpha', 1e-4, 1e2, log=True),\n",
    "        'solver': trial.suggest_categorical('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'])\n",
    "    }\n",
    "\n",
    "    # Initialize and train the Ridge Classifier model with the suggested hyperparameters\n",
    "    ridge_clf = RidgeClassifier(**params)\n",
    "    ridge_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = ridge_clf.predict(X_val)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and their corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Use the best hyperparameters to train the final Ridge Classifier model\n",
    "final_ridge_clf = RidgeClassifier(**best_params)\n",
    "final_ridge_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best Ridge Classifier model\n",
    "y_test_pred = final_ridge_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "\n",
    "# Best Hyperparameters: {'alpha': 0.00010687964225283955, 'solver': 'saga'}\n",
    "# Best Validation Accuracy: 88.34%\n",
    "# Test Accuracy: 86.86%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "248b29a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 13:54:51,257] A new study created in memory with name: no-name-f53f3ed6-3c8a-46cd-9089-2f620d30997a\n",
      "[I 2024-01-24 13:54:51,266] Trial 0 finished with value: 0.9574468085106383 and parameters: {'alpha': 2.619412789107737, 'solver': 'cholesky'}. Best is trial 0 with value: 0.9574468085106383.\n",
      "[I 2024-01-24 13:54:51,288] Trial 1 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.0004242677786956592, 'solver': 'sparse_cg'}. Best is trial 0 with value: 0.9574468085106383.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:51,753] Trial 2 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0015938822149380884, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:51,771] Trial 3 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.15376279022291767, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:51,785] Trial 4 finished with value: 0.9787234042553191 and parameters: {'alpha': 3.947575746568873, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:51,790] Trial 5 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.07633149507714619, 'solver': 'svd'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:52,389] Trial 6 finished with value: 0.9787234042553191 and parameters: {'alpha': 1.1261417711429649, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:52,393] Trial 7 finished with value: 0.9574468085106383 and parameters: {'alpha': 3.351484960490713, 'solver': 'cholesky'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:52,397] Trial 8 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.12497815418815719, 'solver': 'auto'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:52,821] Trial 9 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.17512950329590352, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:53,289] Trial 10 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.00046096052198874943, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 13:54:53,306] Trial 11 finished with value: 0.9787234042553191 and parameters: {'alpha': 71.50206777872619, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:53,322] Trial 12 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0021976733529730473, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:53,338] Trial 13 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.005893759793287844, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:53,804] Trial 14 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.00010583981757750326, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:54,231] Trial 15 finished with value: 0.9787234042553191 and parameters: {'alpha': 56.876089204640714, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:54,238] Trial 16 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.014565812081966752, 'solver': 'auto'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:54,249] Trial 17 finished with value: 0.9787234042553191 and parameters: {'alpha': 11.800520485230338, 'solver': 'svd'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:54,283] Trial 18 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.735135328505697, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:54,827] Trial 19 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.02218518734340314, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:54,843] Trial 20 finished with value: 0.9787234042553191 and parameters: {'alpha': 10.321954128334491, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:55,311] Trial 21 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.7368197985195528, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:55,776] Trial 22 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.7657462537784002, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:56,241] Trial 23 finished with value: 0.9787234042553191 and parameters: {'alpha': 8.172171152978917, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:56,708] Trial 24 finished with value: 0.9787234042553191 and parameters: {'alpha': 3.62748064819823, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:57,175] Trial 25 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.03281602657635239, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:57,182] Trial 26 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.3951710900504891, 'solver': 'svd'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:57,201] Trial 27 finished with value: 0.9787234042553191 and parameters: {'alpha': 28.81002019119931, 'solver': 'auto'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:57,209] Trial 28 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.0032772617143056407, 'solver': 'cholesky'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:57,723] Trial 29 finished with value: 0.9787234042553191 and parameters: {'alpha': 1.3140133660249194, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:57,743] Trial 30 finished with value: 0.9574468085106383 and parameters: {'alpha': 2.8624655473839153, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:58,172] Trial 31 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.2945609479699013, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:58,603] Trial 32 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.049426051457651554, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:59,047] Trial 33 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.2907880633296738, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:59,067] Trial 34 finished with value: 0.9574468085106383 and parameters: {'alpha': 1.6362695672125733, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:54:59,074] Trial 35 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.0006962089544830324, 'solver': 'cholesky'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:59,505] Trial 36 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.17808924234831297, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 13:54:59,522] Trial 37 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.1007455421880084, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:54:59,992] Trial 38 finished with value: 0.9787234042553191 and parameters: {'alpha': 5.537816740472411, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:00,010] Trial 39 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.00013175906773884045, 'solver': 'svd'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:00,072] Trial 40 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.00975659858541732, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:00,597] Trial 41 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0003885536873710314, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:01,065] Trial 42 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0009889597507871312, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:01,535] Trial 43 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0003588101799623439, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:01,551] Trial 44 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0015331390419420822, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:01,558] Trial 45 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.000222415623765195, 'solver': 'auto'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:02,031] Trial 46 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.005164246000562374, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:02,047] Trial 47 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.05167977320891017, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:02,054] Trial 48 finished with value: 0.9787234042553191 and parameters: {'alpha': 16.70534351959021, 'solver': 'cholesky'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:02,524] Trial 49 finished with value: 0.9787234042553191 and parameters: {'alpha': 1.100966505730103, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:02,959] Trial 50 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0007459758816599955, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:02,975] Trial 51 finished with value: 0.9787234042553191 and parameters: {'alpha': 78.03049189237245, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:02,993] Trial 52 finished with value: 0.9787234042553191 and parameters: {'alpha': 25.892537638942652, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:03,009] Trial 53 finished with value: 0.9787234042553191 and parameters: {'alpha': 99.431877861056, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:03,026] Trial 54 finished with value: 0.9787234042553191 and parameters: {'alpha': 45.36487019368977, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:03,498] Trial 55 finished with value: 0.9787234042553191 and parameters: {'alpha': 4.866191653789497, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:03,506] Trial 56 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.15144929819648745, 'solver': 'svd'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:04,065] Trial 57 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.42833992213287325, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:04,073] Trial 58 finished with value: 0.9574468085106383 and parameters: {'alpha': 1.7966276146405804, 'solver': 'auto'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:04,092] Trial 59 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.013688255081410451, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:04,564] Trial 60 finished with value: 0.9787234042553191 and parameters: {'alpha': 9.700458513586472, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:04,580] Trial 61 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0022492954264119198, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:04,597] Trial 62 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.002043686648418228, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:04,614] Trial 63 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.00020776013146392997, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:05,049] Trial 64 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0033618469493311076, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:05,067] Trial 65 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.062385737553444544, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:05,088] Trial 66 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.030377027866244986, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:05,095] Trial 67 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.5233450529779071, 'solver': 'cholesky'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:05,566] Trial 68 finished with value: 0.9787234042553191 and parameters: {'alpha': 2.3277472048149885, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:05,998] Trial 69 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0010850312567144613, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:06,049] Trial 70 finished with value: 0.9787234042553191 and parameters: {'alpha': 17.39168593132797, 'solver': 'svd'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:06,088] Trial 71 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.005035820901815471, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:06,112] Trial 72 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0005675129233723339, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:06,154] Trial 73 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.006469248465235369, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:06,727] Trial 74 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.1925671893614582, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:06,746] Trial 75 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0016452323966774701, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:06,754] Trial 76 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.0031361365783620365, 'solver': 'auto'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:07,227] Trial 77 finished with value: 0.9787234042553191 and parameters: {'alpha': 1.0715327826250918, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:07,677] Trial 78 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.02133011577667197, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:07,694] Trial 79 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0002791117616262399, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:07,715] Trial 80 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.09842766485210731, 'solver': 'sparse_cg'}. Best is trial 2 with value: 0.9787234042553191.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:08,187] Trial 81 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.00011293437543228017, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:08,668] Trial 82 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0011926938888234112, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:09,145] Trial 83 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0006114522708762769, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:09,623] Trial 84 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.00014036726547599253, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:09,630] Trial 85 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.008651151954759543, 'solver': 'cholesky'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:10,101] Trial 86 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.22739636352487216, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:10,118] Trial 87 finished with value: 0.9787234042553191 and parameters: {'alpha': 4.311600471691125, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:10,551] Trial 88 finished with value: 0.9787234042553191 and parameters: {'alpha': 7.417649609502458, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:11,021] Trial 89 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.00017235862113192606, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:11,037] Trial 90 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.00031426485248109014, 'solver': 'svd'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:11,557] Trial 91 finished with value: 0.9787234042553191 and parameters: {'alpha': 67.84885461564247, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:11,992] Trial 92 finished with value: 0.9787234042553191 and parameters: {'alpha': 42.95795074987609, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:12,431] Trial 93 finished with value: 0.9787234042553191 and parameters: {'alpha': 29.358587684958728, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:12,449] Trial 94 finished with value: 0.9787234042553191 and parameters: {'alpha': 48.24427339563006, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:12,456] Trial 95 finished with value: 0.9574468085106383 and parameters: {'alpha': 0.6017181702941812, 'solver': 'auto'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:12,889] Trial 96 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.000434814529834729, 'solver': 'sag'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:13,360] Trial 97 finished with value: 0.9787234042553191 and parameters: {'alpha': 16.153867106743277, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "[I 2024-01-24 13:55:13,376] Trial 98 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0007667823350642113, 'solver': 'lsqr'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 13:55:13,849] Trial 99 finished with value: 0.9787234042553191 and parameters: {'alpha': 0.0024865593954732155, 'solver': 'saga'}. Best is trial 2 with value: 0.9787234042553191.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 0.0015938822149380884, 'solver': 'saga'}\n",
      "Best Validation Accuracy: 97.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 85.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'X_train' and 'y_train' are your training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'alpha': trial.suggest_float('alpha', 1e-4, 1e2, log=True),\n",
    "        'solver': trial.suggest_categorical('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'])\n",
    "    }\n",
    "\n",
    "    # Initialize and train the Ridge Classifier model with the suggested hyperparameters\n",
    "    ridge_clf = RidgeClassifier(**params)\n",
    "    ridge_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = ridge_clf.predict(X_val)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and their corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Use the best hyperparameters to train the final Ridge Classifier model\n",
    "final_ridge_clf = RidgeClassifier(**best_params)\n",
    "final_ridge_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best Ridge Classifier model\n",
    "y_test_pred = final_ridge_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {accuracy_test * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9a6f14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeClassifier(alpha=0.00016956386509426897, solver=&#x27;lsqr&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RidgeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.RidgeClassifier.html\">?<span>Documentation for RidgeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RidgeClassifier(alpha=0.00016956386509426897, solver=&#x27;lsqr&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RidgeClassifier(alpha=0.00016956386509426897, solver='lsqr')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params={'alpha': 0.00016956386509426897, 'solver': 'lsqr'}\n",
    "# best_params={'alpha': 0.0015938822149380884, 'solver': 'saga'}\n",
    "# best_params={'alpha': 0.003361829053719938, 'solver': 'saga'}\n",
    "final_ridge_clf = RidgeClassifier(**best_params)\n",
    "final_ridge_clf.fit(X, y)\n",
    "# y_test_pred = final_ridge_clf.predict(X_test)\n",
    "# accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "# print(f\"Test Accuracy: {accuracy_test * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09418b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Hyperparameters: {'alpha': 0.00016956386509426897, 'solver': 'lsqr'}\n",
    "Best Validation Accuracy: 92.31%\n",
    "Test Accuracy: 86.86%\n",
    "    \n",
    "    \n",
    "# Best Hyperparameters: {'alpha': 0.0015938822149380884, 'solver': 'saga'}\n",
    "# Best Validation Accuracy: 97.87%\n",
    "# Test Accuracy: 85.14%\n",
    "\n",
    "# Best Hyperparameters: {'alpha': 0.003361829053719938, 'solver': 'saga'}\n",
    "# Best Validation Accuracy: 90.99%\n",
    "# Test Accuracy: 91.18%\n",
    "      \n",
    "      \n",
    "# Classifier Performance on Test Set:\n",
    "# Neural Network: 86.88%\n",
    "# Support Vector Machine: 83.75%\n",
    "# Random Forest: 81.25%\n",
    "# Gradient Boosting: 80.00%\n",
    "# K-Nearest Neighbors: 80.00%\n",
    "# Logistic Regression: 80.00%\n",
    "# Decision Tree: 75.62%\n",
    "# Naive Bayes: 51.88%\n",
    "\n",
    "# Classifier Performance on Validation Set:\n",
    "# Neural Network: 86.27%\n",
    "# Support Vector Machine: 82.75%\n",
    "# Logistic Regression: 82.75%\n",
    "# K-Nearest Neighbors: 76.86%\n",
    "# Random Forest: 74.90%\n",
    "# Gradient Boosting: 74.51%\n",
    "# Decision Tree: 72.16%\n",
    "# Naive Bayes: 57.25%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a12848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 01:34:33,311] A new study created in memory with name: no-name-a903a01b-20e8-496a-a52f-9f59443d49b9\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[I 2024-01-24 01:34:34,923] Trial 0 finished with value: 0.4043887147335423 and parameters: {'n_layer_1': 7, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 7.034593705835111e-05, 'learning_rate': 'invscaling'}. Best is trial 0 with value: 0.4043887147335423.\n",
      "[I 2024-01-24 01:34:35,445] Trial 1 finished with value: 0.7711598746081505 and parameters: {'n_layer_1': 11, 'activation': 'relu', 'solver': 'adam', 'alpha': 4.624001988990149e-05, 'learning_rate': 'adaptive'}. Best is trial 1 with value: 0.7711598746081505.\n",
      "[I 2024-01-24 01:34:35,523] Trial 2 finished with value: 0.7931034482758621 and parameters: {'n_layer_1': 6, 'activation': 'identity', 'solver': 'sgd', 'alpha': 0.007153007014095721, 'learning_rate': 'adaptive'}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2024-01-24 01:34:37,439] Trial 3 finished with value: 0.8714733542319749 and parameters: {'n_layer_1': 60, 'activation': 'logistic', 'solver': 'adam', 'alpha': 9.344829139188065e-05, 'learning_rate': 'invscaling'}. Best is trial 3 with value: 0.8714733542319749.\n",
      "[I 2024-01-24 01:34:39,304] Trial 4 finished with value: 0.8746081504702194 and parameters: {'n_layer_1': 91, 'activation': 'logistic', 'solver': 'adam', 'alpha': 4.113011995412719e-05, 'learning_rate': 'adaptive'}. Best is trial 4 with value: 0.8746081504702194.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[I 2024-01-24 01:34:41,328] Trial 5 finished with value: 0.5109717868338558 and parameters: {'n_layer_1': 15, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.0001023053357011191, 'learning_rate': 'constant'}. Best is trial 4 with value: 0.8746081504702194.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 01:34:42,806] Trial 6 finished with value: 0.8871473354231975 and parameters: {'n_layer_1': 16, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.00012858607630920787, 'learning_rate': 'adaptive'}. Best is trial 6 with value: 0.8871473354231975.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[I 2024-01-24 01:34:42,940] Trial 7 finished with value: 0.21630094043887146 and parameters: {'n_layer_1': 90, 'activation': 'identity', 'solver': 'lbfgs', 'alpha': 0.0026479614559150604, 'learning_rate': 'invscaling'}. Best is trial 6 with value: 0.8871473354231975.\n",
      "[I 2024-01-24 01:34:43,342] Trial 8 finished with value: 0.11912225705329153 and parameters: {'n_layer_1': 12, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.03028210916497112, 'learning_rate': 'invscaling'}. Best is trial 6 with value: 0.8871473354231975.\n",
      "[I 2024-01-24 01:34:45,036] Trial 9 finished with value: 0.8871473354231975 and parameters: {'n_layer_1': 85, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0009181552437903038, 'learning_rate': 'constant'}. Best is trial 6 with value: 0.8871473354231975.\n",
      "[I 2024-01-24 01:34:45,662] Trial 10 finished with value: 0.13166144200626959 and parameters: {'n_layer_1': 38, 'activation': 'relu', 'solver': 'sgd', 'alpha': 1.1682515770671202e-05, 'learning_rate': 'adaptive'}. Best is trial 6 with value: 0.8871473354231975.\n",
      "[I 2024-01-24 01:34:48,995] Trial 11 finished with value: 0.8996865203761756 and parameters: {'n_layer_1': 65, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0014841521399290604, 'learning_rate': 'constant'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "[I 2024-01-24 01:34:52,912] Trial 12 finished with value: 0.8808777429467085 and parameters: {'n_layer_1': 55, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0007392749998407598, 'learning_rate': 'constant'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 01:34:57,097] Trial 13 finished with value: 0.8840125391849529 and parameters: {'n_layer_1': 35, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0003777790569318597, 'learning_rate': 'constant'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "[I 2024-01-24 01:35:01,733] Trial 14 finished with value: 0.8683385579937304 and parameters: {'n_layer_1': 73, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.006522214297377676, 'learning_rate': 'adaptive'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "[I 2024-01-24 01:35:02,813] Trial 15 finished with value: 0.7617554858934169 and parameters: {'n_layer_1': 31, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.00022192467862742744, 'learning_rate': 'constant'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "[I 2024-01-24 01:35:06,822] Trial 16 finished with value: 0.8683385579937304 and parameters: {'n_layer_1': 70, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.002551285830072801, 'learning_rate': 'adaptive'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "[I 2024-01-24 01:35:06,930] Trial 17 finished with value: 0.12852664576802508 and parameters: {'n_layer_1': 46, 'activation': 'identity', 'solver': 'sgd', 'alpha': 0.08008614859117875, 'learning_rate': 'constant'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "[I 2024-01-24 01:35:07,004] Trial 18 finished with value: 0.11285266457680251 and parameters: {'n_layer_1': 28, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.00026478774231817383, 'learning_rate': 'constant'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "[I 2024-01-24 01:35:09,882] Trial 19 finished with value: 0.8463949843260188 and parameters: {'n_layer_1': 67, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 1.4765319488885971e-05, 'learning_rate': 'adaptive'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "[I 2024-01-24 01:35:14,148] Trial 20 finished with value: 0.8871473354231975 and parameters: {'n_layer_1': 48, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0027519144255500113, 'learning_rate': 'adaptive'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "[I 2024-01-24 01:35:15,306] Trial 21 finished with value: 0.877742946708464 and parameters: {'n_layer_1': 82, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0007142231706310481, 'learning_rate': 'constant'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "[I 2024-01-24 01:35:16,348] Trial 22 finished with value: 0.8714733542319749 and parameters: {'n_layer_1': 98, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0014554512884449732, 'learning_rate': 'constant'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "[I 2024-01-24 01:35:18,078] Trial 23 finished with value: 0.8871473354231975 and parameters: {'n_layer_1': 79, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0065840482811840425, 'learning_rate': 'constant'}. Best is trial 11 with value: 0.8996865203761756.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 01:35:19,310] Trial 24 finished with value: 0.8808777429467085 and parameters: {'n_layer_1': 21, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0003697255745000313, 'learning_rate': 'constant'}. Best is trial 11 with value: 0.8996865203761756.\n",
      "[I 2024-01-24 01:35:19,974] Trial 25 finished with value: 0.9028213166144201 and parameters: {'n_layer_1': 80, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0010703303099399992, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:35:20,082] Trial 26 finished with value: 0.12852664576802508 and parameters: {'n_layer_1': 60, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.01742889622562204, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:35:20,342] Trial 27 finished with value: 0.11285266457680251 and parameters: {'n_layer_1': 1, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.00014940312964721933, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[I 2024-01-24 01:35:20,401] Trial 28 finished with value: 0.14106583072100312 and parameters: {'n_layer_1': 43, 'activation': 'identity', 'solver': 'lbfgs', 'alpha': 0.001492345442138892, 'learning_rate': 'invscaling'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:35:21,306] Trial 29 finished with value: 0.8808777429467085 and parameters: {'n_layer_1': 56, 'activation': 'tanh', 'solver': 'adam', 'alpha': 2.5858406639891642e-05, 'learning_rate': 'adaptive'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[I 2024-01-24 01:35:28,767] Trial 30 finished with value: 0.8338557993730408 and parameters: {'n_layer_1': 73, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.0004918864056307925, 'learning_rate': 'invscaling'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:35:30,011] Trial 31 finished with value: 0.8871473354231975 and parameters: {'n_layer_1': 86, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0012021827340363263, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:35:31,731] Trial 32 finished with value: 0.8557993730407524 and parameters: {'n_layer_1': 96, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.004125996038227956, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:35:35,740] Trial 33 finished with value: 0.8871473354231975 and parameters: {'n_layer_1': 78, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0009167400558390249, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:35:37,585] Trial 34 finished with value: 0.8526645768025078 and parameters: {'n_layer_1': 62, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.00018469433900985112, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:35:37,919] Trial 35 finished with value: 0.8808777429467085 and parameters: {'n_layer_1': 86, 'activation': 'relu', 'solver': 'adam', 'alpha': 6.48745622373789e-05, 'learning_rate': 'adaptive'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:35:40,209] Trial 36 finished with value: 0.8840125391849529 and parameters: {'n_layer_1': 67, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0005151439143211863, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:35:40,673] Trial 37 finished with value: 0.8808777429467085 and parameters: {'n_layer_1': 92, 'activation': 'identity', 'solver': 'adam', 'alpha': 0.01798576937980329, 'learning_rate': 'adaptive'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:35:42,597] Trial 38 finished with value: 0.8652037617554859 and parameters: {'n_layer_1': 75, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.00011477399711524452, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[I 2024-01-24 01:35:53,651] Trial 39 finished with value: 0.8495297805642633 and parameters: {'n_layer_1': 85, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.0017348941847035028, 'learning_rate': 'invscaling'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-01-24 01:35:55,233] Trial 40 finished with value: 0.6489028213166145 and parameters: {'n_layer_1': 18, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 3.749242486767674e-05, 'learning_rate': 'adaptive'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:00,817] Trial 41 finished with value: 0.877742946708464 and parameters: {'n_layer_1': 50, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0026397475261219776, 'learning_rate': 'adaptive'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:02,083] Trial 42 finished with value: 0.335423197492163 and parameters: {'n_layer_1': 7, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.004435476383958749, 'learning_rate': 'adaptive'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:06,829] Trial 43 finished with value: 0.8557993730407524 and parameters: {'n_layer_1': 64, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.012855731937567456, 'learning_rate': 'adaptive'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:11,099] Trial 44 finished with value: 0.8652037617554859 and parameters: {'n_layer_1': 52, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0040048561013377865, 'learning_rate': 'adaptive'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:16,233] Trial 45 finished with value: 0.877742946708464 and parameters: {'n_layer_1': 41, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.002195193704500896, 'learning_rate': 'adaptive'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:16,302] Trial 46 finished with value: 0.3542319749216301 and parameters: {'n_layer_1': 28, 'activation': 'identity', 'solver': 'sgd', 'alpha': 0.0010304081705312664, 'learning_rate': 'invscaling'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:16,411] Trial 47 finished with value: 0.12225705329153605 and parameters: {'n_layer_1': 94, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.0005780814759645952, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:17,979] Trial 48 finished with value: 0.8401253918495298 and parameters: {'n_layer_1': 79, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.00035870646310191974, 'learning_rate': 'adaptive'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:23,813] Trial 49 finished with value: 0.8495297805642633 and parameters: {'n_layer_1': 89, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.003241169368127247, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 01:36:31,532] Trial 50 finished with value: 0.8338557993730408 and parameters: {'n_layer_1': 69, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 7.585577005154996e-05, 'learning_rate': 'adaptive'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:33,223] Trial 51 finished with value: 0.896551724137931 and parameters: {'n_layer_1': 80, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.005987675092852193, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:35,360] Trial 52 finished with value: 0.8463949843260188 and parameters: {'n_layer_1': 83, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.004694813994691457, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:37,564] Trial 53 finished with value: 0.890282131661442 and parameters: {'n_layer_1': 74, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.011384504536914544, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:39,723] Trial 54 finished with value: 0.8871473354231975 and parameters: {'n_layer_1': 75, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.07350976350716593, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:41,083] Trial 55 finished with value: 0.890282131661442 and parameters: {'n_layer_1': 89, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.031634475098167955, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:43,561] Trial 56 finished with value: 0.8495297805642633 and parameters: {'n_layer_1': 90, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.04818726501663205, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:45,212] Trial 57 finished with value: 0.8401253918495298 and parameters: {'n_layer_1': 80, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.010000440915016054, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:46,816] Trial 58 finished with value: 0.8526645768025078 and parameters: {'n_layer_1': 70, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.03291784897347225, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:47,125] Trial 59 finished with value: 0.8840125391849529 and parameters: {'n_layer_1': 99, 'activation': 'identity', 'solver': 'adam', 'alpha': 0.028546543554070172, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:47,558] Trial 60 finished with value: 0.8714733542319749 and parameters: {'n_layer_1': 75, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.009841677185000581, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:49,043] Trial 61 finished with value: 0.877742946708464 and parameters: {'n_layer_1': 89, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.017881813197418907, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:51,113] Trial 62 finished with value: 0.8840125391849529 and parameters: {'n_layer_1': 83, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.007882079924544046, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:53,125] Trial 63 finished with value: 0.8871473354231975 and parameters: {'n_layer_1': 73, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0428555395082321, 'learning_rate': 'constant'}. Best is trial 25 with value: 0.9028213166144201.\n",
      "[I 2024-01-24 01:36:54,979] Trial 64 finished with value: 0.9059561128526645 and parameters: {'n_layer_1': 65, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0007583028641934986, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:36:56,571] Trial 65 finished with value: 0.8589341692789969 and parameters: {'n_layer_1': 55, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0018964902600359173, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:36:58,265] Trial 66 finished with value: 0.8620689655172413 and parameters: {'n_layer_1': 65, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0003015386546849466, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:37:00,939] Trial 67 finished with value: 0.8746081504702194 and parameters: {'n_layer_1': 58, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.00077420939548364, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:37:02,518] Trial 68 finished with value: 0.8808777429467085 and parameters: {'n_layer_1': 78, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.02158640612558181, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[I 2024-01-24 01:37:10,891] Trial 69 finished with value: 0.8463949843260188 and parameters: {'n_layer_1': 61, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.005732620062452467, 'learning_rate': 'invscaling'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:37:13,051] Trial 70 finished with value: 0.8652037617554859 and parameters: {'n_layer_1': 71, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.013428178951896566, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:37:14,777] Trial 71 finished with value: 0.8871473354231975 and parameters: {'n_layer_1': 87, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0012120608724837606, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:37:16,316] Trial 72 finished with value: 0.8652037617554859 and parameters: {'n_layer_1': 94, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0006331766967609317, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:37:18,467] Trial 73 finished with value: 0.8808777429467085 and parameters: {'n_layer_1': 83, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.00020390485917308476, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:37:20,977] Trial 74 finished with value: 0.8840125391849529 and parameters: {'n_layer_1': 80, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0008479944918581778, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:37:22,079] Trial 75 finished with value: 0.890282131661442 and parameters: {'n_layer_1': 23, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.00044731089557677146, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:37:23,215] Trial 76 finished with value: 0.8526645768025078 and parameters: {'n_layer_1': 10, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0004090884081717043, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:37:23,433] Trial 77 finished with value: 0.8683385579937304 and parameters: {'n_layer_1': 22, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.00016741901117532334, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:37:23,596] Trial 78 finished with value: 0.8652037617554859 and parameters: {'n_layer_1': 17, 'activation': 'identity', 'solver': 'adam', 'alpha': 0.00011770619209666193, 'learning_rate': 'constant'}. Best is trial 64 with value: 0.9059561128526645.\n",
      "[I 2024-01-24 01:37:24,518] Trial 79 finished with value: 0.15047021943573669 and parameters: {'n_layer_1': 34, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0014600605763248988, 'learning_rate': 'invscaling'}. Best is trial 64 with value: 0.9059561128526645.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_layer_1': 65, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0007583028641934986, 'learning_rate': 'constant'}\n",
      "Best Validation Accuracy: 90.60%\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'X_train', 'X_val', 'y_train', 'y_val' are your training and validation sets\n",
    "# Replace them with your actual data\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'hidden_layer_sizes': (trial.suggest_int('n_layer_1', 1, 100),),\n",
    "        'activation': trial.suggest_categorical('activation', ['identity', 'logistic', 'tanh', 'relu']),\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'sgd', 'adam']),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-5, 1e-1, log=True),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', ['constant', 'invscaling', 'adaptive']),\n",
    "    }\n",
    "\n",
    "    # Initialize and train the MLPClassifier with the suggested hyperparameters\n",
    "    mlp_clf = MLPClassifier(random_state=42, max_iter=1000, **params)\n",
    "    mlp_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = mlp_clf.predict(X_val)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=80)  # You can adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters and their corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9312caa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with Best SVM Model: 90.00%\n"
     ]
    }
   ],
   "source": [
    "# Use the best hyperparameters to train the final SVM model\n",
    "best_params={'hidden_layer_sizes': 65, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0007583028641934986, 'learning_rate': 'constant'}\n",
    "final_clf = MLPClassifier(\n",
    "    random_state=42,\n",
    "    max_iter=1000,  # You can adjust max_iter based on your needs\n",
    "    **best_params\n",
    ")\n",
    "final_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best SVM model\n",
    "y_test_pred_svm = final_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM model on the test set\n",
    "test_accuracy_svm = accuracy_score(y_test, y_test_pred_svm)\n",
    "print(f\"Test Accuracy with Best SVM Model: {test_accuracy_svm * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "283dc07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the neural network model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add input layer\n",
    "\n",
    "# Add hidden layers\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Add output layer\n",
    "model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cea0d32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "40/40 [==============================] - 1s 4ms/step - loss: 160.2230 - accuracy: 0.1601 - val_loss: 9.8030 - val_accuracy: 0.3542\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 31.9557 - accuracy: 0.2433 - val_loss: 3.0021 - val_accuracy: 0.3730\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 12.4463 - accuracy: 0.3383 - val_loss: 1.3614 - val_accuracy: 0.6207\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.2126 - accuracy: 0.3689 - val_loss: 0.9143 - val_accuracy: 0.6897\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.1301 - accuracy: 0.4278 - val_loss: 0.8333 - val_accuracy: 0.6646\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3088 - accuracy: 0.4725 - val_loss: 0.6329 - val_accuracy: 0.7712\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.7931 - accuracy: 0.5016 - val_loss: 0.7367 - val_accuracy: 0.7367\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.6045 - accuracy: 0.5345 - val_loss: 0.6913 - val_accuracy: 0.7492\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4615 - accuracy: 0.5589 - val_loss: 0.6754 - val_accuracy: 0.7868\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3077 - accuracy: 0.5667 - val_loss: 0.5704 - val_accuracy: 0.8401\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3431 - accuracy: 0.5612 - val_loss: 0.4746 - val_accuracy: 0.8527\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.1258 - accuracy: 0.6013 - val_loss: 0.5395 - val_accuracy: 0.8370\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.2156 - accuracy: 0.5738 - val_loss: 0.4931 - val_accuracy: 0.8621\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.1469 - accuracy: 0.5761 - val_loss: 0.5534 - val_accuracy: 0.8119\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0985 - accuracy: 0.5816 - val_loss: 0.5429 - val_accuracy: 0.7994\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0265 - accuracy: 0.6052 - val_loss: 0.4483 - val_accuracy: 0.7806\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0301 - accuracy: 0.6162 - val_loss: 0.4166 - val_accuracy: 0.8088\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9524 - accuracy: 0.6264 - val_loss: 0.4469 - val_accuracy: 0.8182\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9927 - accuracy: 0.6107 - val_loss: 0.4485 - val_accuracy: 0.8527\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9218 - accuracy: 0.6303 - val_loss: 0.3862 - val_accuracy: 0.8276\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9159 - accuracy: 0.6421 - val_loss: 0.5041 - val_accuracy: 0.8464\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8598 - accuracy: 0.6381 - val_loss: 0.4277 - val_accuracy: 0.8527\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8524 - accuracy: 0.6538 - val_loss: 0.3558 - val_accuracy: 0.8213\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9273 - accuracy: 0.6350 - val_loss: 0.3796 - val_accuracy: 0.8150\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7869 - accuracy: 0.6845 - val_loss: 0.3514 - val_accuracy: 0.8558\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8127 - accuracy: 0.6593 - val_loss: 0.4030 - val_accuracy: 0.8495\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8465 - accuracy: 0.6240 - val_loss: 0.3579 - val_accuracy: 0.8683\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7831 - accuracy: 0.6625 - val_loss: 0.3804 - val_accuracy: 0.8715\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8302 - accuracy: 0.6397 - val_loss: 0.3679 - val_accuracy: 0.8621\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8128 - accuracy: 0.6641 - val_loss: 0.3118 - val_accuracy: 0.8056\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8601 - accuracy: 0.6460 - val_loss: 0.3207 - val_accuracy: 0.8339\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8376 - accuracy: 0.6476 - val_loss: 0.3115 - val_accuracy: 0.8495\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8014 - accuracy: 0.6538 - val_loss: 0.2918 - val_accuracy: 0.8495\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7585 - accuracy: 0.6688 - val_loss: 0.2963 - val_accuracy: 0.8621\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7528 - accuracy: 0.6719 - val_loss: 0.3026 - val_accuracy: 0.8746\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7873 - accuracy: 0.6601 - val_loss: 0.3075 - val_accuracy: 0.8464\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7703 - accuracy: 0.6625 - val_loss: 0.3225 - val_accuracy: 0.8683\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7930 - accuracy: 0.6421 - val_loss: 0.2852 - val_accuracy: 0.8746\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8327 - accuracy: 0.6272 - val_loss: 0.3452 - val_accuracy: 0.8464\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8322 - accuracy: 0.6468 - val_loss: 0.3686 - val_accuracy: 0.7962\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8933 - accuracy: 0.6303 - val_loss: 0.3787 - val_accuracy: 0.8589\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8773 - accuracy: 0.6115 - val_loss: 0.4396 - val_accuracy: 0.7900\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9086 - accuracy: 0.6044 - val_loss: 0.4376 - val_accuracy: 0.7837\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8724 - accuracy: 0.6413 - val_loss: 0.4399 - val_accuracy: 0.7680\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8565 - accuracy: 0.6295 - val_loss: 0.4366 - val_accuracy: 0.7900\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8276 - accuracy: 0.6358 - val_loss: 0.3493 - val_accuracy: 0.8025\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8336 - accuracy: 0.6468 - val_loss: 0.3391 - val_accuracy: 0.8589\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7919 - accuracy: 0.6601 - val_loss: 0.4021 - val_accuracy: 0.7743\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8203 - accuracy: 0.6586 - val_loss: 0.3271 - val_accuracy: 0.8339\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7606 - accuracy: 0.6743 - val_loss: 0.3137 - val_accuracy: 0.8621\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7758 - accuracy: 0.6719 - val_loss: 0.2896 - val_accuracy: 0.8464\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.6860 - val_loss: 0.2584 - val_accuracy: 0.8652\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6900 - val_loss: 0.2387 - val_accuracy: 0.8840\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7067 - accuracy: 0.6907 - val_loss: 0.2391 - val_accuracy: 0.8840\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7397 - accuracy: 0.6884 - val_loss: 0.2688 - val_accuracy: 0.8683\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7601 - accuracy: 0.6648 - val_loss: 0.3010 - val_accuracy: 0.8495\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7459 - accuracy: 0.6852 - val_loss: 0.2767 - val_accuracy: 0.8903\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.6978 - val_loss: 0.3004 - val_accuracy: 0.8840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.6947 - val_loss: 0.3066 - val_accuracy: 0.8809\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.6962 - val_loss: 0.2601 - val_accuracy: 0.8746\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.6813 - val_loss: 0.2490 - val_accuracy: 0.8527\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.6947 - val_loss: 0.2673 - val_accuracy: 0.8715\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6994 - val_loss: 0.2974 - val_accuracy: 0.8433\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6766 - val_loss: 0.3209 - val_accuracy: 0.8777\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6923 - val_loss: 0.2191 - val_accuracy: 0.8840\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.6947 - val_loss: 0.2958 - val_accuracy: 0.8527\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7188 - accuracy: 0.6609 - val_loss: 0.2470 - val_accuracy: 0.8621\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.6876 - val_loss: 0.2368 - val_accuracy: 0.8809\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.6805 - val_loss: 0.2892 - val_accuracy: 0.8370\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.6758 - val_loss: 0.2833 - val_accuracy: 0.8307\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.7041 - val_loss: 0.2672 - val_accuracy: 0.8715\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.7166 - val_loss: 0.2178 - val_accuracy: 0.8777\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.7308 - val_loss: 0.2922 - val_accuracy: 0.8809\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6852 - val_loss: 0.2333 - val_accuracy: 0.8715\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.7151 - val_loss: 0.3015 - val_accuracy: 0.8495\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6962 - val_loss: 0.2494 - val_accuracy: 0.8809\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.7174 - val_loss: 0.2760 - val_accuracy: 0.8871\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.7174 - val_loss: 0.2034 - val_accuracy: 0.8903\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.7159 - val_loss: 0.2019 - val_accuracy: 0.8871\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.7072 - val_loss: 0.2233 - val_accuracy: 0.8871\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6145 - accuracy: 0.7088 - val_loss: 0.3096 - val_accuracy: 0.7712\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.6688 - val_loss: 0.2135 - val_accuracy: 0.9122\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6688 - val_loss: 0.2474 - val_accuracy: 0.8871\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7018 - accuracy: 0.6766 - val_loss: 0.2538 - val_accuracy: 0.8871\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6758 - val_loss: 0.2111 - val_accuracy: 0.8871\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6829 - val_loss: 0.2213 - val_accuracy: 0.8840\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6876 - val_loss: 0.2585 - val_accuracy: 0.8809\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7084 - accuracy: 0.6695 - val_loss: 0.2840 - val_accuracy: 0.8652\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7546 - accuracy: 0.6688 - val_loss: 0.2596 - val_accuracy: 0.8652\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6939 - val_loss: 0.2778 - val_accuracy: 0.8715\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.7869 - accuracy: 0.6499 - val_loss: 0.2680 - val_accuracy: 0.8777\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.6876 - val_loss: 0.2110 - val_accuracy: 0.8871\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6970 - val_loss: 0.2193 - val_accuracy: 0.8809\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7562 - accuracy: 0.6499 - val_loss: 0.2783 - val_accuracy: 0.8715\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.6735 - val_loss: 0.2516 - val_accuracy: 0.8652\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7058 - accuracy: 0.6774 - val_loss: 0.2062 - val_accuracy: 0.8840\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7552 - accuracy: 0.6601 - val_loss: 0.2135 - val_accuracy: 0.8871\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.6735 - val_loss: 0.2672 - val_accuracy: 0.8652\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.6774 - val_loss: 0.2457 - val_accuracy: 0.8809\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.6868 - val_loss: 0.2561 - val_accuracy: 0.8495\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.6797 - val_loss: 0.2138 - val_accuracy: 0.8840\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.6727 - val_loss: 0.2124 - val_accuracy: 0.8840\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.7009 - val_loss: 0.2022 - val_accuracy: 0.8871\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.6900 - val_loss: 0.2300 - val_accuracy: 0.8715\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.6688 - val_loss: 0.2263 - val_accuracy: 0.8777\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6805 - val_loss: 0.2044 - val_accuracy: 0.8840\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7146 - accuracy: 0.6688 - val_loss: 0.2692 - val_accuracy: 0.8370\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7320 - accuracy: 0.6484 - val_loss: 0.2125 - val_accuracy: 0.8840\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7730 - accuracy: 0.6468 - val_loss: 0.2379 - val_accuracy: 0.8809\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7123 - accuracy: 0.6648 - val_loss: 0.2205 - val_accuracy: 0.8840\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.6664 - val_loss: 0.2645 - val_accuracy: 0.8370\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.6695 - val_loss: 0.3050 - val_accuracy: 0.8527\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7237 - accuracy: 0.6625 - val_loss: 0.2057 - val_accuracy: 0.8840\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.6593 - val_loss: 0.2210 - val_accuracy: 0.8809\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7048 - accuracy: 0.6609 - val_loss: 0.1908 - val_accuracy: 0.8871\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.6711 - val_loss: 0.2420 - val_accuracy: 0.8589\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6852 - val_loss: 0.2380 - val_accuracy: 0.8621\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6790 - val_loss: 0.2088 - val_accuracy: 0.8934\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.7064 - val_loss: 0.2010 - val_accuracy: 0.8840\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.6837 - val_loss: 0.2361 - val_accuracy: 0.8809\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.6648 - val_loss: 0.1855 - val_accuracy: 0.8809\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.6907 - val_loss: 0.1936 - val_accuracy: 0.8840\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6664 - val_loss: 0.2431 - val_accuracy: 0.8840\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.6837 - val_loss: 0.1945 - val_accuracy: 0.8840\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.6947 - val_loss: 0.2179 - val_accuracy: 0.8809\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6750 - val_loss: 0.1922 - val_accuracy: 0.8809\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.6711 - val_loss: 0.2196 - val_accuracy: 0.8840\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.7033 - val_loss: 0.2342 - val_accuracy: 0.8621\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.7009 - val_loss: 0.2525 - val_accuracy: 0.8652\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7128 - accuracy: 0.6633 - val_loss: 0.3153 - val_accuracy: 0.7806\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.6978 - val_loss: 0.2310 - val_accuracy: 0.8746\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.6750 - val_loss: 0.2102 - val_accuracy: 0.8871\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6994 - val_loss: 0.2063 - val_accuracy: 0.8840\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6994 - val_loss: 0.2267 - val_accuracy: 0.8809\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6797 - val_loss: 0.2632 - val_accuracy: 0.8245\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6915 - val_loss: 0.2126 - val_accuracy: 0.8840\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.6931 - val_loss: 0.2191 - val_accuracy: 0.8809\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6962 - val_loss: 0.2251 - val_accuracy: 0.8840\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.6954 - val_loss: 0.2496 - val_accuracy: 0.8558\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.6782 - val_loss: 0.2144 - val_accuracy: 0.8777\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.7004 - accuracy: 0.6703 - val_loss: 0.3050 - val_accuracy: 0.8182\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.6852 - val_loss: 0.2178 - val_accuracy: 0.8809\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.6727 - val_loss: 0.2478 - val_accuracy: 0.8589\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.6695 - val_loss: 0.1979 - val_accuracy: 0.8840\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.6821 - val_loss: 0.2398 - val_accuracy: 0.8621\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6246 - accuracy: 0.6962 - val_loss: 0.1961 - val_accuracy: 0.8966\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.6868 - val_loss: 0.3145 - val_accuracy: 0.7712\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.6884 - val_loss: 0.2378 - val_accuracy: 0.8621\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.6664 - val_loss: 0.2708 - val_accuracy: 0.8558\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.6719 - val_loss: 0.2170 - val_accuracy: 0.8840\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.6829 - val_loss: 0.2372 - val_accuracy: 0.8777\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6719 - val_loss: 0.2414 - val_accuracy: 0.8966\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7181 - accuracy: 0.6507 - val_loss: 0.3329 - val_accuracy: 0.7962\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7378 - accuracy: 0.6625 - val_loss: 0.2043 - val_accuracy: 0.8934\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7083 - accuracy: 0.6774 - val_loss: 0.2647 - val_accuracy: 0.8339\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.6845 - val_loss: 0.3079 - val_accuracy: 0.7962\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.6852 - val_loss: 0.2665 - val_accuracy: 0.8245\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.6797 - val_loss: 0.2879 - val_accuracy: 0.8119\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7250 - accuracy: 0.6727 - val_loss: 0.2521 - val_accuracy: 0.8401\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8277 - accuracy: 0.6413 - val_loss: 0.2846 - val_accuracy: 0.7994\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8353 - accuracy: 0.6342 - val_loss: 0.3438 - val_accuracy: 0.7806\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.6821 - val_loss: 0.2698 - val_accuracy: 0.8370\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.6774 - val_loss: 0.2880 - val_accuracy: 0.7962\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7000 - accuracy: 0.6562 - val_loss: 0.2832 - val_accuracy: 0.8558\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8203 - accuracy: 0.6405 - val_loss: 0.3287 - val_accuracy: 0.7994\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8303 - accuracy: 0.6342 - val_loss: 0.2436 - val_accuracy: 0.8652\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7502 - accuracy: 0.6593 - val_loss: 0.3133 - val_accuracy: 0.7994\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6931 - val_loss: 0.2312 - val_accuracy: 0.8527\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7086 - accuracy: 0.6680 - val_loss: 0.2665 - val_accuracy: 0.8213\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8013 - accuracy: 0.6295 - val_loss: 0.2680 - val_accuracy: 0.8245\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.6774 - val_loss: 0.2508 - val_accuracy: 0.8433\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7960 - accuracy: 0.6232 - val_loss: 0.1992 - val_accuracy: 0.8840\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6790 - val_loss: 0.2838 - val_accuracy: 0.7994\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.6578 - val_loss: 0.2408 - val_accuracy: 0.8433\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6860 - val_loss: 0.3416 - val_accuracy: 0.7837\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.6797 - val_loss: 0.4078 - val_accuracy: 0.7712\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.6719 - val_loss: 0.2718 - val_accuracy: 0.8119\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.6429 - val_loss: 0.4037 - val_accuracy: 0.7712\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.6766 - val_loss: 0.2879 - val_accuracy: 0.8119\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.6735 - val_loss: 0.2581 - val_accuracy: 0.8182\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.7080 - val_loss: 0.3537 - val_accuracy: 0.7774\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.7080 - val_loss: 0.2221 - val_accuracy: 0.8652\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.6860 - val_loss: 0.2169 - val_accuracy: 0.8621\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6868 - val_loss: 0.3278 - val_accuracy: 0.7962\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.6766 - val_loss: 0.3665 - val_accuracy: 0.7868\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6931 - val_loss: 0.3057 - val_accuracy: 0.8056\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6641 - val_loss: 0.3322 - val_accuracy: 0.7837\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.6939 - val_loss: 0.2779 - val_accuracy: 0.8433\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6719 - val_loss: 0.2744 - val_accuracy: 0.8339\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.6609 - val_loss: 0.3088 - val_accuracy: 0.7994\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6986 - val_loss: 0.3503 - val_accuracy: 0.7994\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7743 - accuracy: 0.6436 - val_loss: 0.2776 - val_accuracy: 0.8025\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.6468 - val_loss: 0.2269 - val_accuracy: 0.8558\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.6735 - val_loss: 0.3291 - val_accuracy: 0.7994\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7128 - accuracy: 0.6562 - val_loss: 0.2149 - val_accuracy: 0.8777\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6735 - val_loss: 0.3012 - val_accuracy: 0.7994\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.6593 - val_loss: 0.4495 - val_accuracy: 0.7743\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7160 - accuracy: 0.6727 - val_loss: 0.2500 - val_accuracy: 0.8621\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7561 - accuracy: 0.6327 - val_loss: 0.2828 - val_accuracy: 0.8433\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7220 - accuracy: 0.6719 - val_loss: 0.2831 - val_accuracy: 0.8150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16d873d50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have X_train, y_train, X_val, y_val\n",
    "model.fit(X_train, y_train, epochs=200, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fe228b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 256)               11008     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52680 (205.78 KB)\n",
      "Trainable params: 52680 (205.78 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e062a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 01:13:52,316] A new study created in memory with name: no-name-f3325196-6325-4feb-bc92-3d6ecfa3bd6e\n",
      "[I 2024-01-24 01:13:53,413] Trial 0 finished with value: 0.8777429461479187 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 323, 'dropout_layer_0': 0.30400574242267187, 'lr': 0.003927064113359008}. Best is trial 0 with value: 0.8777429461479187.\n",
      "[I 2024-01-24 01:13:55,121] Trial 1 finished with value: 0.852664589881897 and parameters: {'num_hidden_layers': 3, 'units_layer_0': 82, 'dropout_layer_0': 0.43621616299654425, 'units_layer_1': 173, 'dropout_layer_1': 0.2948673069049142, 'units_layer_2': 166, 'dropout_layer_2': 0.4081403055916702, 'lr': 0.009520909828257627}. Best is trial 0 with value: 0.8777429461479187.\n",
      "[I 2024-01-24 01:13:56,796] Trial 2 finished with value: 0.846394956111908 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 242, 'dropout_layer_0': 0.31293173180566725, 'units_layer_1': 94, 'dropout_layer_1': 0.3387752416510282, 'lr': 0.0006455457187990421}. Best is trial 0 with value: 0.8777429461479187.\n",
      "[I 2024-01-24 01:13:58,925] Trial 3 finished with value: 0.8401253819465637 and parameters: {'num_hidden_layers': 3, 'units_layer_0': 224, 'dropout_layer_0': 0.3994857130711876, 'units_layer_1': 487, 'dropout_layer_1': 0.2549790929553079, 'units_layer_2': 392, 'dropout_layer_2': 0.2491546520604286, 'lr': 0.0008063135324958862}. Best is trial 0 with value: 0.8777429461479187.\n",
      "[I 2024-01-24 01:14:00,529] Trial 4 finished with value: 0.852664589881897 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 373, 'dropout_layer_0': 0.32136750477209824, 'units_layer_1': 404, 'dropout_layer_1': 0.36792469347490997, 'lr': 0.0008288220587668743}. Best is trial 0 with value: 0.8777429461479187.\n",
      "[I 2024-01-24 01:14:02,313] Trial 5 finished with value: 0.8620689511299133 and parameters: {'num_hidden_layers': 3, 'units_layer_0': 213, 'dropout_layer_0': 0.3921016568721104, 'units_layer_1': 140, 'dropout_layer_1': 0.32884639612104116, 'units_layer_2': 319, 'dropout_layer_2': 0.31859883366940317, 'lr': 0.00046797545133062547}. Best is trial 0 with value: 0.8777429461479187.\n",
      "[I 2024-01-24 01:14:03,820] Trial 6 finished with value: 0.8871473073959351 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 318, 'dropout_layer_0': 0.2609271014436155, 'units_layer_1': 223, 'dropout_layer_1': 0.2571617238454473, 'lr': 0.0014908600294298113}. Best is trial 6 with value: 0.8871473073959351.\n",
      "[I 2024-01-24 01:14:05,246] Trial 7 finished with value: 0.8652037382125854 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 246, 'dropout_layer_0': 0.41157778227943675, 'units_layer_1': 183, 'dropout_layer_1': 0.3356200426528367, 'lr': 0.0002856120288567097}. Best is trial 6 with value: 0.8871473073959351.\n",
      "[I 2024-01-24 01:14:06,678] Trial 8 finished with value: 0.8620689511299133 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 146, 'dropout_layer_0': 0.4141965865594846, 'units_layer_1': 291, 'dropout_layer_1': 0.45108016483440905, 'lr': 0.001279325499510009}. Best is trial 6 with value: 0.8871473073959351.\n",
      "[I 2024-01-24 01:14:08,112] Trial 9 finished with value: 0.8746081590652466 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 406, 'dropout_layer_0': 0.4655540255256664, 'lr': 0.00016233246063595787}. Best is trial 6 with value: 0.8871473073959351.\n",
      "[I 2024-01-24 01:14:09,226] Trial 10 finished with value: 0.8746081590652466 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 509, 'dropout_layer_0': 0.208046697417431, 'lr': 0.0018917276082915414}. Best is trial 6 with value: 0.8871473073959351.\n",
      "[I 2024-01-24 01:14:10,317] Trial 11 finished with value: 0.8683385848999023 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 349, 'dropout_layer_0': 0.26224630970117874, 'lr': 0.0035488165077340417}. Best is trial 6 with value: 0.8871473073959351.\n",
      "[I 2024-01-24 01:14:11,398] Trial 12 finished with value: 0.8714733719825745 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 313, 'dropout_layer_0': 0.26222447840073726, 'lr': 0.0038478630263570155}. Best is trial 6 with value: 0.8871473073959351.\n",
      "[I 2024-01-24 01:14:12,499] Trial 13 finished with value: 0.8746081590652466 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 424, 'dropout_layer_0': 0.2703920933479814, 'lr': 0.002969960015052225}. Best is trial 6 with value: 0.8871473073959351.\n",
      "[I 2024-01-24 01:14:14,031] Trial 14 finished with value: 0.8432601690292358 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 304, 'dropout_layer_0': 0.20794958278470277, 'units_layer_1': 267, 'dropout_layer_1': 0.21702989491845864, 'lr': 0.007433674579054985}. Best is trial 6 with value: 0.8871473073959351.\n",
      "[I 2024-01-24 01:14:15,153] Trial 15 finished with value: 0.8934169411659241 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 474, 'dropout_layer_0': 0.34632382101590703, 'lr': 0.001659028429006634}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:17,177] Trial 16 finished with value: 0.8432601690292358 and parameters: {'num_hidden_layers': 3, 'units_layer_0': 508, 'dropout_layer_0': 0.35451145799866346, 'units_layer_1': 307, 'dropout_layer_1': 0.2012418809853441, 'units_layer_2': 91, 'dropout_layer_2': 0.48699549901847694, 'lr': 0.0016870720247204203}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:18,839] Trial 17 finished with value: 0.846394956111908 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 461, 'dropout_layer_0': 0.356218891320906, 'units_layer_1': 378, 'dropout_layer_1': 0.40677929790269757, 'lr': 0.00033712197460465275}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:20,297] Trial 18 finished with value: 0.8338558077812195 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 447, 'dropout_layer_0': 0.49045939236488006, 'lr': 0.0020354143711478496}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:21,709] Trial 19 finished with value: 0.8808777332305908 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 162, 'dropout_layer_0': 0.23991231457959555, 'units_layer_1': 228, 'dropout_layer_1': 0.2803323357577039, 'lr': 0.00012154909290199304}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:23,557] Trial 20 finished with value: 0.7492163181304932 and parameters: {'num_hidden_layers': 3, 'units_layer_0': 389, 'dropout_layer_0': 0.29207083528179556, 'units_layer_1': 74, 'dropout_layer_1': 0.494319079993809, 'units_layer_2': 490, 'dropout_layer_2': 0.2191686523836597, 'lr': 0.001157261533602968}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:24,932] Trial 21 finished with value: 0.8683385848999023 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 156, 'dropout_layer_0': 0.23967295148740192, 'units_layer_1': 224, 'dropout_layer_1': 0.2693957372899581, 'lr': 0.00014504066146410954}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:26,276] Trial 22 finished with value: 0.8871473073959351 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 69, 'dropout_layer_0': 0.23538881370680714, 'units_layer_1': 233, 'dropout_layer_1': 0.2458264268934677, 'lr': 0.00021755569426789803}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:27,731] Trial 23 finished with value: 0.8746081590652466 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 107, 'dropout_layer_0': 0.33178206543906513, 'units_layer_1': 348, 'dropout_layer_1': 0.23683859683035505, 'lr': 0.00024387679232985369}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:28,801] Trial 24 finished with value: 0.8589341640472412 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 270, 'dropout_layer_0': 0.23257206514373122, 'lr': 0.0005385016809846633}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:30,259] Trial 25 finished with value: 0.8777429461479187 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 189, 'dropout_layer_0': 0.3749525902323723, 'units_layer_1': 253, 'dropout_layer_1': 0.30518097423872703, 'lr': 0.001373185046142468}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:32,316] Trial 26 finished with value: 0.8495298027992249 and parameters: {'num_hidden_layers': 3, 'units_layer_0': 67, 'dropout_layer_0': 0.2830956335718555, 'units_layer_1': 149, 'dropout_layer_1': 0.23239679371052663, 'units_layer_2': 215, 'dropout_layer_2': 0.49851227791776276, 'lr': 0.0025582563893800517}. Best is trial 15 with value: 0.8934169411659241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 01:14:33,889] Trial 27 finished with value: 0.7680251002311707 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 358, 'dropout_layer_0': 0.22914682814591522, 'units_layer_1': 330, 'dropout_layer_1': 0.3644220487851273, 'lr': 0.005503547615995007}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:35,017] Trial 28 finished with value: 0.8495298027992249 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 474, 'dropout_layer_0': 0.33393856767818364, 'lr': 0.0008979536455565512}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:36,096] Trial 29 finished with value: 0.8808777332305908 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 333, 'dropout_layer_0': 0.29362655636481894, 'lr': 0.0004086036928365907}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:37,568] Trial 30 finished with value: 0.8401253819465637 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 290, 'dropout_layer_0': 0.2611299796613483, 'units_layer_1': 204, 'dropout_layer_1': 0.2543978874660554, 'lr': 0.004949285608844516}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:38,979] Trial 31 finished with value: 0.8620689511299133 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 123, 'dropout_layer_0': 0.239558420134917, 'units_layer_1': 229, 'dropout_layer_1': 0.28267796141129964, 'lr': 0.00010603357465375785}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:40,355] Trial 32 finished with value: 0.8840125203132629 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 94, 'dropout_layer_0': 0.22019147101372336, 'units_layer_1': 256, 'dropout_layer_1': 0.30522084799624843, 'lr': 0.0001834560397533595}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:41,702] Trial 33 finished with value: 0.8401253819465637 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 91, 'dropout_layer_0': 0.2020191131203911, 'units_layer_1': 118, 'dropout_layer_1': 0.297801608647502, 'lr': 0.00019535457631571806}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:44,081] Trial 34 finished with value: 0.8589341640472412 and parameters: {'num_hidden_layers': 3, 'units_layer_0': 133, 'dropout_layer_0': 0.22086668323054753, 'units_layer_1': 267, 'dropout_layer_1': 0.31284248806022213, 'units_layer_2': 490, 'dropout_layer_2': 0.36438232664699677, 'lr': 0.00023156680032623294}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:45,448] Trial 35 finished with value: 0.852664589881897 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 94, 'dropout_layer_0': 0.308095037185905, 'units_layer_1': 183, 'dropout_layer_1': 0.24572799147566765, 'lr': 0.0007744584875316467}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:46,949] Trial 36 finished with value: 0.8871473073959351 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 179, 'dropout_layer_0': 0.25189875849211246, 'units_layer_1': 305, 'dropout_layer_1': 0.2030894924226803, 'lr': 0.0006012205611811863}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:48,994] Trial 37 finished with value: 0.8871473073959351 and parameters: {'num_hidden_layers': 3, 'units_layer_0': 187, 'dropout_layer_0': 0.27696911854173045, 'units_layer_1': 432, 'dropout_layer_1': 0.20464232613089378, 'units_layer_2': 328, 'dropout_layer_2': 0.29130083452269767, 'lr': 0.0006140910941306482}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:50,520] Trial 38 finished with value: 0.8840125203132629 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 242, 'dropout_layer_0': 0.25175037510741016, 'units_layer_1': 322, 'dropout_layer_1': 0.22919594898115345, 'lr': 0.00037955111039440244}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:51,599] Trial 39 finished with value: 0.8871473073959351 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 266, 'dropout_layer_0': 0.3237941421795709, 'lr': 0.001029527840162545}. Best is trial 15 with value: 0.8934169411659241.\n",
      "[I 2024-01-24 01:14:53,124] Trial 40 finished with value: 0.9028213024139404 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 209, 'dropout_layer_0': 0.4239484247016319, 'units_layer_1': 360, 'dropout_layer_1': 0.2691198915661924, 'lr': 0.0015926970604577663}. Best is trial 40 with value: 0.9028213024139404.\n",
      "[I 2024-01-24 01:14:54,645] Trial 41 finished with value: 0.8714733719825745 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 217, 'dropout_layer_0': 0.450565122753682, 'units_layer_1': 369, 'dropout_layer_1': 0.2607459041016223, 'lr': 0.0014997973224728097}. Best is trial 40 with value: 0.9028213024139404.\n",
      "[I 2024-01-24 01:14:56,566] Trial 42 finished with value: 0.815047025680542 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 194, 'dropout_layer_0': 0.3903483039897266, 'units_layer_1': 443, 'dropout_layer_1': 0.2185369190842595, 'lr': 0.0021510013402852557}. Best is trial 40 with value: 0.9028213024139404.\n",
      "[I 2024-01-24 01:14:58,095] Trial 43 finished with value: 0.8840125203132629 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 262, 'dropout_layer_0': 0.42505897379231894, 'units_layer_1': 289, 'dropout_layer_1': 0.28147762126779846, 'lr': 0.0024381251971458385}. Best is trial 40 with value: 0.9028213024139404.\n",
      "[I 2024-01-24 01:14:59,592] Trial 44 finished with value: 0.8808777332305908 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 167, 'dropout_layer_0': 0.3800556834233723, 'units_layer_1': 357, 'dropout_layer_1': 0.21961558054632951, 'lr': 0.0006935411969272783}. Best is trial 40 with value: 0.9028213024139404.\n",
      "[I 2024-01-24 01:15:01,183] Trial 45 finished with value: 0.8557993769645691 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 237, 'dropout_layer_0': 0.46154295519652355, 'units_layer_1': 511, 'dropout_layer_1': 0.24344012949105212, 'lr': 0.0012140127397277844}. Best is trial 40 with value: 0.9028213024139404.\n",
      "[I 2024-01-24 01:15:02,600] Trial 46 finished with value: 0.8871473073959351 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 68, 'dropout_layer_0': 0.4857958173387553, 'units_layer_1': 417, 'dropout_layer_1': 0.2646075257023351, 'lr': 0.001655768226288363}. Best is trial 40 with value: 0.9028213024139404.\n",
      "[I 2024-01-24 01:15:03,639] Trial 47 finished with value: 0.8714733719825745 and parameters: {'num_hidden_layers': 1, 'units_layer_0': 123, 'dropout_layer_0': 0.4367294286758345, 'lr': 0.0009441202077127207}. Best is trial 40 with value: 0.9028213024139404.\n",
      "[I 2024-01-24 01:15:05,465] Trial 48 finished with value: 0.8244513869285583 and parameters: {'num_hidden_layers': 3, 'units_layer_0': 207, 'dropout_layer_0': 0.2521241649746213, 'units_layer_1': 395, 'dropout_layer_1': 0.20040625023331202, 'units_layer_2': 66, 'dropout_layer_2': 0.42116976274133244, 'lr': 0.0033710517730485257}. Best is trial 40 with value: 0.9028213024139404.\n",
      "[I 2024-01-24 01:15:06,949] Trial 49 finished with value: 0.8965517282485962 and parameters: {'num_hidden_layers': 2, 'units_layer_0': 415, 'dropout_layer_0': 0.34365910485708695, 'units_layer_1': 156, 'dropout_layer_1': 0.39806175421375534, 'lr': 0.0017933668433486396}. Best is trial 40 with value: 0.9028213024139404.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 1s 1ms/step - loss: 0.8635 - accuracy: 0.6774\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8516\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2823 - accuracy: 0.8540\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2529 - accuracy: 0.8721\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.8587\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.8587\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.8603\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.8626\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2317 - accuracy: 0.8571\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.8548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d5287ad0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "import optuna\n",
    "\n",
    "# Assuming num_features is the number of features in your input data\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "def build_model(trial):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Add input layer\n",
    "    model.add(layers.InputLayer(input_shape=(num_features,)))\n",
    "\n",
    "    # Determine the number of hidden layers\n",
    "    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 3)\n",
    "\n",
    "    # Add hidden layers with batch normalization\n",
    "    for i in range(num_hidden_layers):\n",
    "        units = trial.suggest_int(f'units_layer_{i}', 64, 512)\n",
    "        model.add(layers.Dense(units))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Activation('relu'))\n",
    "        dropout_rate = trial.suggest_float(f'dropout_layer_{i}', 0.2, 0.5)\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    # Add output layer\n",
    "    model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    model = build_model(trial)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    _, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "    return val_accuracy\n",
    "\n",
    "# Create an Optuna study and optimize the model\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best hyperparameters from the study\n",
    "best_params = study.best_params\n",
    "best_model = build_model(optuna.trial.FixedTrial(best_params))\n",
    "\n",
    "# Train the best model on the full training set\n",
    "best_model.fit(X_train, y_train, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e506a2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.8673\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.8681\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.8838\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.8681\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.8736\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.8619\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.8783\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.8681\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.8634\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.8697\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.8658\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.8666\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.8642\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.8689\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1896 - accuracy: 0.8776\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.8697\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.8791\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.8666\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.8564\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.8673\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.8689\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.8815\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.8626\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.8681\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.8619\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.8548\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 0.8736\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.8619\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.8736\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.8650\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.8697\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.8689\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.8587\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.8626\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.8768\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.8752\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.8713\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.8689\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.8721\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.8760\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.8721\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.8579\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.8838\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.8705\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.8697\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.8642\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.8556\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.8658\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.8673\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.8626\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.8768\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.8524\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.8673\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.8744\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.8728\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.8626\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.8650\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.8721\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.8673\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.8673\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.8721\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.8736\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.8673\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.8626\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.8642\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.8728\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.8736\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.8626\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.8744\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.8776\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.8595\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.8838\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.8626\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.8807\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.8697\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.8697\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.8705\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.8626\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.8713\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.8736\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.8611\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.8681\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.8634\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.8493\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.8689\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.8673\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.8689\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.8595\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.8736\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.8697\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.8626\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.8681\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.8666\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.8681\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.8634\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.8689\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.8603\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.8603\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.8815\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.8760\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.8823\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.8776\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.8642\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.8768\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.8666\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.8681\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.8776\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.8768\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.8689\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.8689\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.8642\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.8721\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.8595\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.8721\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.8697\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.8721\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.8634\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.8721\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.8760\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.8650\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.8705\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.8760\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.8642\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.8603\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.8736\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.8846\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.8705\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.8830\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.8846\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.8666\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.8838\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.8666\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.8705\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.8626\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.8728\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.8776\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.8713\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.8760\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.8634\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.8689\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.8815\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.8713\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.8689\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.8791\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.8705\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.8658\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 0.8650\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.8642\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.8673\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.8689\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.8611\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.8650\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.8830\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.8666\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.8721\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.8823\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.8736\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.8681\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.8728\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.8666\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.8736\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.8697\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.8634\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.8752\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.8760\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.8807\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.8673\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.8736\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.8728\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.8658\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.8728\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.8532\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.8760\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.8721\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.8728\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.8705\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.8634\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.8689\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.8752\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.8658\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.8721\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.8736\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.8760\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.8673\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.8791\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.8760\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.8705\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.8752\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.8666\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.8768\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.8619\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.8752\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.8658\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.8689\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.8736\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.8760\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.8697\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.8728\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.8673\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.8783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d33dfbd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the best model on the full training set\n",
    "best_model.fit(X_train, y_train, epochs=200, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d017aa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "40/40 [==============================] - 1s 5ms/step - loss: 23.8578 - accuracy: 0.2449 - val_loss: 1.4841 - val_accuracy: 0.5110\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.5011 - accuracy: 0.3736 - val_loss: 0.9693 - val_accuracy: 0.6301\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3122 - accuracy: 0.4325 - val_loss: 0.7815 - val_accuracy: 0.7743\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3664 - accuracy: 0.4215 - val_loss: 0.8765 - val_accuracy: 0.6176\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.5340 - accuracy: 0.3352 - val_loss: 0.8409 - val_accuracy: 0.7429\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4529 - accuracy: 0.3752 - val_loss: 1.5267 - val_accuracy: 0.4577\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.7016 - accuracy: 0.2936 - val_loss: 1.3006 - val_accuracy: 0.4734\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.6042 - accuracy: 0.3187 - val_loss: 1.1295 - val_accuracy: 0.4890\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.5619 - accuracy: 0.3187 - val_loss: 1.0925 - val_accuracy: 0.6426\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.5484 - accuracy: 0.3093 - val_loss: 1.1426 - val_accuracy: 0.4671\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.6370 - accuracy: 0.2779 - val_loss: 1.3126 - val_accuracy: 0.4890\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.6397 - accuracy: 0.3014 - val_loss: 1.3479 - val_accuracy: 0.4828\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.6716 - accuracy: 0.2653 - val_loss: 1.2629 - val_accuracy: 0.5047\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.7118 - accuracy: 0.2457 - val_loss: 1.6399 - val_accuracy: 0.3699\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.6072 - accuracy: 0.3328 - val_loss: 1.0097 - val_accuracy: 0.5737\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4531 - accuracy: 0.3925 - val_loss: 0.9685 - val_accuracy: 0.6082\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3936 - accuracy: 0.4058 - val_loss: 0.9580 - val_accuracy: 0.6426\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4184 - accuracy: 0.4160 - val_loss: 0.9993 - val_accuracy: 0.6113\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4095 - accuracy: 0.3995 - val_loss: 0.7706 - val_accuracy: 0.6646\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4068 - accuracy: 0.4105 - val_loss: 0.9648 - val_accuracy: 0.5956\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3074 - accuracy: 0.4451 - val_loss: 0.9380 - val_accuracy: 0.5361\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4208 - accuracy: 0.4184 - val_loss: 1.0804 - val_accuracy: 0.6019\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.5865 - accuracy: 0.3713 - val_loss: 0.7573 - val_accuracy: 0.6708\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4363 - accuracy: 0.3870 - val_loss: 1.0788 - val_accuracy: 0.4263\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4111 - accuracy: 0.4027 - val_loss: 0.9578 - val_accuracy: 0.5956\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.5287 - accuracy: 0.3642 - val_loss: 1.1864 - val_accuracy: 0.3950\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.7667 - accuracy: 0.2394 - val_loss: 1.1886 - val_accuracy: 0.4169\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.5464 - accuracy: 0.3242 - val_loss: 1.0434 - val_accuracy: 0.6019\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3110 - accuracy: 0.4584 - val_loss: 0.6967 - val_accuracy: 0.6708\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3116 - accuracy: 0.4568 - val_loss: 0.9009 - val_accuracy: 0.6520\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3480 - accuracy: 0.4419 - val_loss: 0.8323 - val_accuracy: 0.6552\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.1197 - accuracy: 0.5440 - val_loss: 0.5665 - val_accuracy: 0.8495\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.1098 - accuracy: 0.5502 - val_loss: 0.6409 - val_accuracy: 0.7837\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3668 - accuracy: 0.4498 - val_loss: 0.9626 - val_accuracy: 0.6646\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.2693 - accuracy: 0.5008 - val_loss: 1.0566 - val_accuracy: 0.5674\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.1862 - accuracy: 0.5024 - val_loss: 0.5716 - val_accuracy: 0.7994\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0105 - accuracy: 0.5997 - val_loss: 0.6638 - val_accuracy: 0.7053\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0164 - accuracy: 0.5926 - val_loss: 0.4440 - val_accuracy: 0.8809\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9320 - accuracy: 0.6460 - val_loss: 0.5334 - val_accuracy: 0.8652\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9618 - accuracy: 0.6232 - val_loss: 0.4199 - val_accuracy: 0.8245\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9592 - accuracy: 0.6068 - val_loss: 0.3702 - val_accuracy: 0.8025\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8279 - accuracy: 0.6515 - val_loss: 0.4809 - val_accuracy: 0.7868\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8112 - accuracy: 0.6562 - val_loss: 0.4893 - val_accuracy: 0.8433\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7439 - accuracy: 0.6994 - val_loss: 0.4167 - val_accuracy: 0.8652\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8260 - accuracy: 0.6672 - val_loss: 0.5393 - val_accuracy: 0.8527\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8016 - accuracy: 0.6852 - val_loss: 0.4099 - val_accuracy: 0.8652\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7527 - accuracy: 0.6947 - val_loss: 0.4311 - val_accuracy: 0.8245\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7507 - accuracy: 0.6915 - val_loss: 0.4340 - val_accuracy: 0.8464\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7813 - accuracy: 0.6782 - val_loss: 0.3869 - val_accuracy: 0.8527\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8539 - accuracy: 0.6358 - val_loss: 0.4170 - val_accuracy: 0.8464\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8261 - accuracy: 0.6633 - val_loss: 0.5850 - val_accuracy: 0.7618\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8086 - accuracy: 0.6782 - val_loss: 0.4506 - val_accuracy: 0.7524\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.7229 - val_loss: 0.3963 - val_accuracy: 0.8809\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7280 - accuracy: 0.6813 - val_loss: 0.3894 - val_accuracy: 0.8433\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7122 - accuracy: 0.6868 - val_loss: 0.3337 - val_accuracy: 0.8401\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7370 - val_loss: 0.3001 - val_accuracy: 0.8746\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7606 - val_loss: 0.1807 - val_accuracy: 0.8966\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.7386 - val_loss: 0.3507 - val_accuracy: 0.8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8519 - accuracy: 0.6727 - val_loss: 0.4916 - val_accuracy: 0.7837\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7855 - accuracy: 0.7237 - val_loss: 0.3199 - val_accuracy: 0.8746\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.7331 - val_loss: 0.2365 - val_accuracy: 0.8903\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.7425 - val_loss: 0.2447 - val_accuracy: 0.8997\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7567 - val_loss: 0.2123 - val_accuracy: 0.8715\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7653 - val_loss: 0.2309 - val_accuracy: 0.8871\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7865 - val_loss: 0.2114 - val_accuracy: 0.8777\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7912 - val_loss: 0.2854 - val_accuracy: 0.8464\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8120 - accuracy: 0.6523 - val_loss: 0.6554 - val_accuracy: 0.7398\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9282 - accuracy: 0.5973 - val_loss: 0.6483 - val_accuracy: 0.7367\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9569 - accuracy: 0.6083 - val_loss: 1.1775 - val_accuracy: 0.6552\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.2376 - accuracy: 0.5487 - val_loss: 0.3554 - val_accuracy: 0.8589\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8124 - accuracy: 0.6358 - val_loss: 0.4650 - val_accuracy: 0.7837\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7958 - accuracy: 0.6562 - val_loss: 0.5378 - val_accuracy: 0.7586\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.7174 - val_loss: 0.3527 - val_accuracy: 0.8871\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.8030 - val_loss: 0.3005 - val_accuracy: 0.8652\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8061 - val_loss: 0.2953 - val_accuracy: 0.8871\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7983 - val_loss: 0.1947 - val_accuracy: 0.8777\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8038 - val_loss: 0.2051 - val_accuracy: 0.8934\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8187 - val_loss: 0.2202 - val_accuracy: 0.8777\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8226 - val_loss: 0.2398 - val_accuracy: 0.8809\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.7465 - val_loss: 0.1824 - val_accuracy: 0.8840\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8046 - val_loss: 0.2061 - val_accuracy: 0.8871\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8038 - val_loss: 0.2361 - val_accuracy: 0.8652\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8250 - val_loss: 0.1730 - val_accuracy: 0.8715\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7983 - val_loss: 0.2578 - val_accuracy: 0.8621\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8195 - val_loss: 0.1703 - val_accuracy: 0.8840\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8336 - val_loss: 0.1638 - val_accuracy: 0.8934\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8407 - val_loss: 0.1763 - val_accuracy: 0.8871\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.8548 - val_loss: 0.1648 - val_accuracy: 0.8871\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8556 - val_loss: 0.1538 - val_accuracy: 0.9091\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.8564 - val_loss: 0.1642 - val_accuracy: 0.8871\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8642 - val_loss: 0.1723 - val_accuracy: 0.8809\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.8532 - val_loss: 0.1692 - val_accuracy: 0.8871\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8430 - val_loss: 0.1882 - val_accuracy: 0.8840\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.8509 - val_loss: 0.1629 - val_accuracy: 0.8871\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2691 - accuracy: 0.8469 - val_loss: 0.1686 - val_accuracy: 0.8871\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.8516 - val_loss: 0.1607 - val_accuracy: 0.8809\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8462 - val_loss: 0.6346 - val_accuracy: 0.8464\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7959 - val_loss: 0.1715 - val_accuracy: 0.8589\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8148 - val_loss: 0.1628 - val_accuracy: 0.8715\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8438 - val_loss: 0.1637 - val_accuracy: 0.8871\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8344 - val_loss: 0.1734 - val_accuracy: 0.8809\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8257 - val_loss: 0.1693 - val_accuracy: 0.8809\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.8556 - val_loss: 0.1571 - val_accuracy: 0.8871\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8516 - val_loss: 0.1701 - val_accuracy: 0.8809\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.8587 - val_loss: 0.2241 - val_accuracy: 0.8715\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2676 - accuracy: 0.8611 - val_loss: 0.1756 - val_accuracy: 0.8840\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.8485 - val_loss: 0.1602 - val_accuracy: 0.8871\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.8658 - val_loss: 0.1602 - val_accuracy: 0.8871\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8375 - val_loss: 0.1595 - val_accuracy: 0.8871\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.8548 - val_loss: 0.1775 - val_accuracy: 0.8840\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.8571 - val_loss: 0.1708 - val_accuracy: 0.8746\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.8634 - val_loss: 0.1599 - val_accuracy: 0.8809\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.8689 - val_loss: 0.1590 - val_accuracy: 0.8871\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.8493 - val_loss: 0.1752 - val_accuracy: 0.8777\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.8501 - val_loss: 0.1613 - val_accuracy: 0.8903\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8226 - val_loss: 0.1963 - val_accuracy: 0.8652\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8305 - val_loss: 0.2277 - val_accuracy: 0.8840\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8422 - val_loss: 0.1690 - val_accuracy: 0.8871\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2401 - accuracy: 0.8446 - val_loss: 0.1824 - val_accuracy: 0.8809\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.8501 - val_loss: 0.1637 - val_accuracy: 0.8903\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.8564 - val_loss: 0.1800 - val_accuracy: 0.8621\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.8548 - val_loss: 0.1568 - val_accuracy: 0.8871\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.8587 - val_loss: 0.1635 - val_accuracy: 0.8527\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.8430 - val_loss: 0.1779 - val_accuracy: 0.8715\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8352 - val_loss: 0.1872 - val_accuracy: 0.8715\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.8532 - val_loss: 0.1641 - val_accuracy: 0.8840\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.8579 - val_loss: 0.3494 - val_accuracy: 0.8307\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7920 - val_loss: 0.2182 - val_accuracy: 0.8715\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.8462 - val_loss: 0.1644 - val_accuracy: 0.8527\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.8501 - val_loss: 0.1595 - val_accuracy: 0.8871\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.8359 - val_loss: 0.1740 - val_accuracy: 0.8809\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8532 - val_loss: 0.1619 - val_accuracy: 0.8871\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.8705 - val_loss: 0.1585 - val_accuracy: 0.8871\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.8532 - val_loss: 0.1617 - val_accuracy: 0.8746\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.8705 - val_loss: 0.1610 - val_accuracy: 0.8871\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.8626 - val_loss: 0.2255 - val_accuracy: 0.8621\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.8571 - val_loss: 0.1611 - val_accuracy: 0.8495\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.8721 - val_loss: 0.1682 - val_accuracy: 0.8840\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8352 - val_loss: 0.2677 - val_accuracy: 0.8715\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.8595 - val_loss: 0.1595 - val_accuracy: 0.8871\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.8642 - val_loss: 0.1726 - val_accuracy: 0.8871\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.8540 - val_loss: 0.1576 - val_accuracy: 0.8871\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.8595 - val_loss: 0.1586 - val_accuracy: 0.8871\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8438 - val_loss: 0.1918 - val_accuracy: 0.8809\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8540 - val_loss: 0.1644 - val_accuracy: 0.8840\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.8681 - val_loss: 0.1623 - val_accuracy: 0.8871\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.8776 - val_loss: 0.1618 - val_accuracy: 0.8558\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.8728 - val_loss: 0.1613 - val_accuracy: 0.8777\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.8666 - val_loss: 0.1604 - val_accuracy: 0.8527\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.8626 - val_loss: 0.1610 - val_accuracy: 0.8370\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.8697 - val_loss: 0.1587 - val_accuracy: 0.8840\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.8752 - val_loss: 0.1661 - val_accuracy: 0.8840\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.8548 - val_loss: 0.1622 - val_accuracy: 0.8871\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.8697 - val_loss: 0.1638 - val_accuracy: 0.8840\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.8642 - val_loss: 0.1597 - val_accuracy: 0.8871\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.8548 - val_loss: 0.1608 - val_accuracy: 0.8871\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.8666 - val_loss: 0.1608 - val_accuracy: 0.8652\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.8721 - val_loss: 0.1615 - val_accuracy: 0.8871\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.8626 - val_loss: 0.2775 - val_accuracy: 0.8150\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8446 - val_loss: 0.1632 - val_accuracy: 0.8840\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.8713 - val_loss: 0.1607 - val_accuracy: 0.8871\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.8611 - val_loss: 0.1642 - val_accuracy: 0.8840\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.8595 - val_loss: 0.1579 - val_accuracy: 0.8903\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.8666 - val_loss: 0.1617 - val_accuracy: 0.8621\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.8611 - val_loss: 0.1594 - val_accuracy: 0.8683\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.8611 - val_loss: 0.1603 - val_accuracy: 0.8683\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.8744 - val_loss: 0.1588 - val_accuracy: 0.8871\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.8697 - val_loss: 0.1647 - val_accuracy: 0.8871\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8493 - val_loss: 0.1636 - val_accuracy: 0.8871\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.8705 - val_loss: 0.1632 - val_accuracy: 0.8871\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8344 - val_loss: 0.1694 - val_accuracy: 0.8840\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.8485 - val_loss: 0.1613 - val_accuracy: 0.8809\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.8595 - val_loss: 0.1589 - val_accuracy: 0.8871\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.8634 - val_loss: 0.1643 - val_accuracy: 0.8777\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.8666 - val_loss: 0.1659 - val_accuracy: 0.8809\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.8430 - val_loss: 0.1602 - val_accuracy: 0.8777\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.8540 - val_loss: 0.1571 - val_accuracy: 0.8871\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.8642 - val_loss: 0.1663 - val_accuracy: 0.8809\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.8689 - val_loss: 0.1577 - val_accuracy: 0.8809\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.8650 - val_loss: 0.1615 - val_accuracy: 0.8652\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.8807 - val_loss: 0.1571 - val_accuracy: 0.8871\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.8681 - val_loss: 0.1571 - val_accuracy: 0.8966\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.8823 - val_loss: 0.1623 - val_accuracy: 0.8871\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.8744 - val_loss: 0.1573 - val_accuracy: 0.8934\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.8736 - val_loss: 0.1637 - val_accuracy: 0.8871\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.8689 - val_loss: 0.1595 - val_accuracy: 0.8527\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.8713 - val_loss: 0.1604 - val_accuracy: 0.8558\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.8728 - val_loss: 0.1576 - val_accuracy: 0.8871\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.8736 - val_loss: 0.1604 - val_accuracy: 0.8840\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.8752 - val_loss: 0.1617 - val_accuracy: 0.8433\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.8603 - val_loss: 0.1597 - val_accuracy: 0.8777\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.8666 - val_loss: 0.1584 - val_accuracy: 0.8495\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.8634 - val_loss: 0.1817 - val_accuracy: 0.8683\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8493 - val_loss: 0.1608 - val_accuracy: 0.8871\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.8571 - val_loss: 0.2038 - val_accuracy: 0.8809\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.7834 - val_loss: 0.2269 - val_accuracy: 0.8652\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8430 - val_loss: 0.1537 - val_accuracy: 0.8966\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.8603 - val_loss: 0.1563 - val_accuracy: 0.8871\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.8579 - val_loss: 0.1577 - val_accuracy: 0.8871\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.8626 - val_loss: 0.1575 - val_accuracy: 0.8934\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'X_train', 'X_val', 'X_test', 'y_train', 'y_val', 'y_test' are your datasets\n",
    "num_classes=8\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(X_train.shape[1:])),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# preferred_model.compile(\n",
    "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  #<-- Note\n",
    "#     optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "# )\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded, epochs=200, validation_data=(X_val, y_val_encoded))\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "# print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1256b15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "preds=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e52f437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1697 - accuracy: 0.8875\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8805e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_ridge_clf2.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(final_ridge_clf, 'final_ridge_clf2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ab82a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[10128]: Class CaptureDelegate is implemented in both /Users/aryansood/anaconda3/lib/python3.11/site-packages/cv2/cv2.abi3.so (0x154112620) and /Users/aryansood/anaconda3/lib/python3.11/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x1503f8860). One of the two will be used. Which one is undefined.\n",
      "objc[10128]: Class CVWindow is implemented in both /Users/aryansood/anaconda3/lib/python3.11/site-packages/cv2/cv2.abi3.so (0x154112670) and /Users/aryansood/anaconda3/lib/python3.11/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x146f10a68). One of the two will be used. Which one is undefined.\n",
      "objc[10128]: Class CVView is implemented in both /Users/aryansood/anaconda3/lib/python3.11/site-packages/cv2/cv2.abi3.so (0x154112698) and /Users/aryansood/anaconda3/lib/python3.11/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x146f10a90). One of the two will be used. Which one is undefined.\n",
      "objc[10128]: Class CVSlider is implemented in both /Users/aryansood/anaconda3/lib/python3.11/site-packages/cv2/cv2.abi3.so (0x1541126c0) and /Users/aryansood/anaconda3/lib/python3.11/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x146f10ab8). One of the two will be used. Which one is undefined.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "/Users/aryansood/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nMLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Make predictions using the pretrained SVM model\u001b[39;00m\n\u001b[1;32m     78\u001b[0m X_frame \u001b[38;5;241m=\u001b[39m hand_landmarks_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m prediction_i \u001b[38;5;241m=\u001b[39m best_svm_model\u001b[38;5;241m.\u001b[39mpredict(X_frame)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction_i)\n\u001b[1;32m     81\u001b[0m predictions \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(np\u001b[38;5;241m.\u001b[39mreshape(np\u001b[38;5;241m.\u001b[39margmax(prediction_i), (\u001b[38;5;241m1\u001b[39m,)))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1159\u001b[0m, in \u001b[0;36mMLPClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the multi-layer perceptron classifier.\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \n\u001b[1;32m   1148\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03m    The predicted classes.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1163\u001b[0m, in \u001b[0;36mMLPClassifier._predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Private predict method with optional input validation\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1163\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pass_fast(X, check_input\u001b[38;5;241m=\u001b[39mcheck_input)\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1166\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:207\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the trained model\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mThis is the same as _forward_pass but does not record the activations\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m    The decision function of the samples for each class in the model.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[0;32m--> 207\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m], reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Initialize first layer\u001b[39;00m\n\u001b[1;32m    210\u001b[0m activation \u001b[38;5;241m=\u001b[39m X\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1003\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1000\u001b[0m     )\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1003\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1004\u001b[0m         array,\n\u001b[1;32m   1005\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1006\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1007\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    127\u001b[0m     X,\n\u001b[1;32m    128\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m    129\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[1;32m    130\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[1;32m    131\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    132\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    133\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m     )\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nMLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# FOR NEURAL\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the pretrained SVM model\n",
    "# best_svm_model = joblib.load('gesture_recognition_model.pkl')\n",
    "# best_svm_model = joblib.load('gesture_recognition_model_better.pkl')\n",
    "# best_svm_model = joblib.load('rfc_model.pkl')\n",
    "best_svm_model = joblib.load('mlpc1.pkl')\n",
    "\n",
    "\n",
    "# Initialize MediaPipe Hand module\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to extract landmarks\n",
    "def get_landmarks(image):\n",
    "    landmark_list = []\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                # Multiply x and y values by image width and height to get pixel values\n",
    "                x = int(landmark.x * image.shape[1])\n",
    "                y = int(landmark.y * image.shape[0])\n",
    "                landmark_list.append((x, y))\n",
    "    return landmark_list\n",
    "\n",
    "# Create a DataFrame to store hand landmarks\n",
    "columns = [f'l{i}_x' for i in range(21)] + [f'l{i}_y' for i in range(21)] + [f'l{i}_z' for i in range(21)]\n",
    "hand_landmarks_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "with mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5) as hands:\n",
    "    # Open the camera\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    # Set the frame width and height\n",
    "#     cap.set(3, 640)\n",
    "#     cap.set(4, 480)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert the BGR image to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame to get hand landmarks\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        # Check if hand landmarks are detected\n",
    "        if results.multi_hand_landmarks:\n",
    "            # Use the landmarks of the first detected hand (assuming one hand in the frame)\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            \n",
    "            # Extract landmark positions\n",
    "            if get_landmarks(frame):\n",
    "                lst=[]\n",
    "                for i in get_landmarks(frame):\n",
    "                    for j in i:\n",
    "                        lst.append(j)\n",
    "                df=pd.DataFrame(lst)\n",
    "\n",
    "                # Append landmark positions to the DataFrame\n",
    "                hand_landmarks_df = pd.concat([hand_landmarks_df, df ], ignore_index=True)\n",
    "\n",
    "                # Display the frame with hand landmarks (optional)\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Make predictions using the pretrained SVM model\n",
    "                X_frame = hand_landmarks_df.iloc[-1].values.reshape(1, -1)\n",
    "                prediction_i = best_svm_model.predict(X_frame)\n",
    "                print(prediction_i)\n",
    "                predictions = label_encoder.inverse_transform(np.reshape(np.argmax(prediction_i), (1,)))\n",
    "\n",
    "                # Decode the predicted label\n",
    "                predicted_gesture = predictions\n",
    "                print(predictions)\n",
    "                # Display the predicted gesture on the frame\n",
    "                cv2.putText(frame, f'Gesture: {predicted_gesture}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Hand Landmarks', frame)\n",
    "\n",
    "        # Break the loop if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "611ce979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 79.94%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have your feature data in X and labels in y\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the HistGradientBoostingClassifier\n",
    "clf = HistGradientBoostingClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc0834dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 88.68%\n",
      "Test Accuracy: 83.12%\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d43efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 01:50:39,189] A new study created in memory with name: no-name-522c8ea8-ade8-49da-99be-f0d8a334d4d4\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_10215/2106196637.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e3)\n",
      "/var/folders/4g/xg0f50gx4dx5gtd5bnslt1kc0000gn/T/ipykernel_10215/2106196637.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-3, 1e3) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have your feature data in X and labels in y\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    C = trial.suggest_loguniform('C', 1e-3, 1e3)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly', 'sigmoid'])\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else None\n",
    "    gamma = trial.suggest_loguniform('gamma', 1e-3, 1e3) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "\n",
    "    # Create and train the SVC with suggested hyperparameters\n",
    "    svc = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma, random_state=42)\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = svc.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Create the Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Train the final SVC model with the best hyperparameters on the entire training set\n",
    "final_svc = SVC(random_state=42, **best_params)\n",
    "final_svc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = final_svc.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Best Validation Accuracy: {study.best_value * 100:.2f}%\")\n",
    "print(f\"Test Accuracy with Best Hyperparameters: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3b08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have your feature data in X and labels in y\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly', 'sigmoid'])\n",
    "    \n",
    "    if kernel == 'poly':\n",
    "        degree = trial.suggest_int('degree', 2, 5)\n",
    "    else:\n",
    "        degree = 3  # Default degree for non-poly kernels\n",
    "       \n",
    "    gamma = trial.suggest_float('gamma', 1e-3, 1e3, log=True) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "\n",
    "    # Create and train the SVC with suggested hyperparameters\n",
    "    svc = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma, random_state=42)\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = svc.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Create the Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Train the final SVC model with the best hyperparameters on the entire training set\n",
    "final_svc = SVC(random_state=42, **best_params)\n",
    "final_svc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = final_svc.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Best Validation Accuracy: {study.best_value * 100:.2f}%\")\n",
    "print(f\"Test Accuracy with Best Hyperparameters: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8090b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
